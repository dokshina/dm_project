{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load movies list\n",
    "movieList = pd.read_csv('movieList.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"http://www.imdb.com/title/\" + \"tt0180093\" + \"/reviews\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ParseMovie(movie_id):\n",
    "    movieReviews = pd.DataFrame(columns = ['review_id', 'rating', 'useful', 'useful_of', \n",
    "                                           'movie_name', 'movie_id', 'numOfReviews',\n",
    "                               'review_name', 'author', 'region', 'date', 'review_text'])\n",
    "    \n",
    "    \n",
    "    #at first let's get info about the movie by id\n",
    "    url = \"http://www.imdb.com/title/\" + movie_id + \"/reviews\"\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    #get movie_name\n",
    "    tn15title = soup.findChild(id=\"tn15title\")\n",
    "    movie_name = tn15title.find_all(\"a\")[0].get_text()\n",
    "    tn15content = soup.find(id=\"tn15content\")\n",
    "    numOfReviews = int(tn15content.find_all(\"table\")[2].get_text().replace(\"\\n\",\" \").split(\" \")[3])\n",
    "    print movie_name, numOfReviews, \"---------------\"\n",
    "    #download reviews\n",
    "    for k in xrange(numOfReviews/10+1):\n",
    "        #create url\n",
    "        start_review = 10*k\n",
    "        url = \"http://www.imdb.com/title/\" + str(movie_id) + \"/reviews?start=\" + str(start_review)\n",
    "        print  (1.0*start_review / numOfReviews)\n",
    "        #download html\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        tn15content = soup.find(id=\"tn15content\")\n",
    "\n",
    "        #delete message about spoilers\n",
    "        tn15_p = list(tn15content.find_all(\"p\"))\n",
    "        len1 = len(tn15_p)\n",
    "        i=0\n",
    "        while(i<len1):\n",
    "            if tn15_p[i].get_text() == u'*** This review may contain spoilers ***':\n",
    "                tn15_p.remove(tn15_p[i])\n",
    "                i =-1\n",
    "                len1 -= 1\n",
    "            i+=1\n",
    "        tn15_p.remove(tn15_p[len1-1])\n",
    "        len1 -= 1 #number of review on the current page\n",
    "\n",
    "        #preparate data for all the reviews on the page\n",
    "        tn15_review = tn15content.find_all(class_='yn')\n",
    "\n",
    "        tn15_small = tn15content.find_all(\"small\")#useful, date, region\n",
    "        review_name = tn15content.find_all(\"h2\")\n",
    "        tn15_div = tn15content.find_all(\"div\")\n",
    "\n",
    "        for i in xrange(len1):\n",
    "            review = {}\n",
    "            review['review_id'] = tn15_review[i].attrs['id'].split(\"_\")[1]\n",
    "            review['review_text'] = tn15_p[i].get_text().replace(\"\\n\", \" \").lower()\n",
    "            review['movie_name'] = movie_name\n",
    "            review['movie_id'] = movie_id\n",
    "            review['numOfReviews'] = numOfReviews\n",
    "            review['review_name'] = review_name[i].get_text()\n",
    "            review['author'] = tn15_div[2*i+0].find_all(\"a\")[1].get_text()\n",
    "\n",
    "            #check if we have rating\n",
    "            if (len(tn15content.find_all('div')[2*i].find_all('img'))) == 1:\n",
    "                review['rating'] = None\n",
    "            else: \n",
    "                review['rating'] = tn15content.find_all(\"div\")[2*i].find_all(\"img\")[1].attrs['alt'].split(\"/\")[0]\n",
    "\n",
    "\n",
    "            #check if we have region and uselful\n",
    "            tn15_small = tn15_div[2*i].find_all('small')\n",
    "\n",
    "            if len(tn15_small) == 3:\n",
    "                review['useful'] = int(tn15_small[0].get_text().split(' ')[0])\n",
    "                review['useful_of'] = int(tn15_small[0].get_text().split(\" \")[3])\n",
    "                review['region'] = tn15_small[1].get_text()[5:]\n",
    "                review['date'] = tn15_small[2].get_text()\n",
    "\n",
    "            elif len(tn15_small) == 1:\n",
    "                review['date'] = tn15_small[0].get_text()\n",
    "                review['useful'] = None\n",
    "                review['useful_of'] = None\n",
    "                review['region'] = None\n",
    "\n",
    "            elif len(tn15_small) == 2:\n",
    "                review['date'] = tn15_small[1].get_text()\n",
    "                if tn15_small[0].get_text()[0] == u'f':\n",
    "                    review['region'] = tn15_small[0].get_text()[5:]\n",
    "                    review['useful'] = None\n",
    "                    review['useful_of'] = None\n",
    "                else:\n",
    "                    review['region'] = None\n",
    "                    review['useful'] = int(tn15_small[0].get_text().split(' ')[0])\n",
    "                    review['useful_of'] = int(tn15_small[0].get_text().split(' ')[3])\n",
    "\n",
    "            movieReviews = movieReviews.append([review], ignore_index=True)\n",
    "    return movieReviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imdb = pd.DataFrame(columns = ['review_id', 'rating', 'useful', 'useful_of', 'movie_name', 'movie_id', 'numOfReviews',\n",
    "                               'review_name', 'author', 'region', 'date', 'review_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Schindler's List 1375 ---------------\n",
      "0.0\n",
      "0.00727272727273\n",
      "0.0145454545455\n",
      "0.0218181818182\n",
      "0.0290909090909\n",
      "0.0363636363636\n",
      "0.0436363636364\n",
      "0.0509090909091\n",
      "0.0581818181818\n",
      "0.0654545454545\n",
      "0.0727272727273\n",
      "0.08\n",
      "0.0872727272727\n",
      "0.0945454545455\n",
      "0.101818181818\n",
      "0.109090909091\n",
      "0.116363636364\n",
      "0.123636363636\n",
      "0.130909090909\n",
      "0.138181818182\n",
      "0.145454545455\n",
      "0.152727272727\n",
      "0.16\n",
      "0.167272727273\n",
      "0.174545454545\n",
      "0.181818181818\n",
      "0.189090909091\n",
      "0.196363636364\n",
      "0.203636363636\n",
      "0.210909090909\n",
      "0.218181818182\n",
      "0.225454545455\n",
      "0.232727272727\n",
      "0.24\n",
      "0.247272727273\n",
      "0.254545454545\n",
      "0.261818181818\n",
      "0.269090909091\n",
      "0.276363636364\n",
      "0.283636363636\n",
      "0.290909090909\n",
      "0.298181818182\n",
      "0.305454545455\n",
      "0.312727272727\n",
      "0.32\n",
      "0.327272727273\n",
      "0.334545454545\n",
      "0.341818181818\n",
      "0.349090909091\n",
      "0.356363636364\n",
      "0.363636363636\n",
      "0.370909090909\n",
      "0.378181818182\n",
      "0.385454545455\n",
      "0.392727272727\n",
      "0.4\n",
      "0.407272727273\n",
      "0.414545454545\n",
      "0.421818181818\n",
      "0.429090909091\n",
      "0.436363636364\n",
      "0.443636363636\n",
      "0.450909090909\n",
      "0.458181818182\n",
      "0.465454545455\n",
      "0.472727272727\n",
      "0.48\n",
      "0.487272727273\n",
      "0.494545454545\n",
      "0.501818181818\n",
      "0.509090909091\n",
      "0.516363636364\n",
      "0.523636363636\n",
      "0.530909090909\n",
      "0.538181818182\n",
      "0.545454545455\n",
      "0.552727272727\n",
      "0.56\n",
      "0.567272727273\n",
      "0.574545454545\n",
      "0.581818181818\n",
      "0.589090909091\n",
      "0.596363636364\n",
      "0.603636363636\n",
      "0.610909090909\n",
      "0.618181818182\n",
      "0.625454545455\n",
      "0.632727272727\n",
      "0.64\n",
      "0.647272727273\n",
      "0.654545454545\n",
      "0.661818181818\n",
      "0.669090909091\n",
      "0.676363636364\n",
      "0.683636363636\n",
      "0.690909090909\n",
      "0.698181818182\n",
      "0.705454545455\n",
      "0.712727272727\n",
      "0.72\n",
      "0.727272727273\n",
      "0.734545454545\n",
      "0.741818181818\n",
      "0.749090909091\n",
      "0.756363636364\n",
      "0.763636363636\n",
      "0.770909090909\n",
      "0.778181818182\n",
      "0.785454545455\n",
      "0.792727272727\n",
      "0.8\n",
      "0.807272727273\n",
      "0.814545454545\n",
      "0.821818181818\n",
      "0.829090909091\n",
      "0.836363636364\n",
      "0.843636363636\n",
      "0.850909090909\n",
      "0.858181818182\n",
      "0.865454545455\n",
      "0.872727272727\n",
      "0.88\n",
      "0.887272727273\n",
      "0.894545454545\n",
      "0.901818181818\n",
      "0.909090909091\n",
      "0.916363636364\n",
      "0.923636363636\n",
      "0.930909090909\n",
      "0.938181818182\n",
      "0.945454545455\n",
      "0.952727272727\n",
      "0.96\n",
      "0.967272727273\n",
      "0.974545454545\n",
      "0.981818181818\n",
      "0.989090909091\n",
      "0.996363636364\n"
     ]
    }
   ],
   "source": [
    "#get reviews from 0 to 99\n",
    "for i in xrange(5,6):\n",
    "    print i\n",
    "    imdb = pd.DataFrame(columns = ['review_id', 'rating', 'useful', 'useful_of', 'movie_name', 'movie_id', 'numOfReviews',\n",
    "                               'review_name', 'author', 'region', 'date', 'review_text'])\n",
    "    \n",
    "    imdb = imdb.append(ParseMovie(movieList.id[i]))\n",
    "    cvs_name = './reviews_' + str(i) +'.csv'\n",
    "    imdb.to_csv(cvs_name, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_inst = CountVectorizer()\n",
    "a = cv_inst.fit_transform(imdb.review_text)\n",
    "result = a.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1375L, 174L)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#выкинем слова, которые встречаются < 100 раз\n",
    "result = result[:, [i for i in range(result.shape[1]) if (200 > result[:, i].sum() and result[:, i].sum() > 100)]]\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8844410203711917"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lnreg = LinearRegression()\n",
    "\n",
    "imdb.rating = imdb.rating.fillna(5)\n",
    "y = imdb.rating.astype(int).values\n",
    "np.random.shuffle(y)\n",
    "\n",
    "lnreg.fit(result[:700], y[:700])\n",
    "pred = lnreg.predict(result[700:]) \n",
    "\n",
    "ar_floor = np.apply_along_axis(np.floor, 0, pred)\n",
    "ar_floor = np.where(ar_floor < 0, 0, ar_floor)\n",
    "ar_floor = np.where(ar_floor > 10, 10, ar_floor)\n",
    "\n",
    "((ar_floor - y[700:]) ** 2).mean() ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etalon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4935747912724455"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((y - y.mean()) ** 2).mean() ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8692494824592356"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((ar_floor - y[700:]) ** 2).mean() ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  8.,   8.,  10.,   3.,   3.,   7.,   9.,   8.,  10.,   8.,   7.,\n",
       "          8.,   5.,   5.,  10.,   7.,  10.,   9.,  10.,   6.,   8.,   7.,\n",
       "          3.,   7.,   7.,   9.,  10.,   7.,   3.,   6.,   6.,   8.,   8.,\n",
       "          4.,   7.,  10.,   9.,   8.,   8.,   7.,   7.,  10.,   8.,   9.,\n",
       "          9.,   6.,   4.,  10.,   6.,   6.]),\n",
       " array([ 9, 10,  5, 10,  5,  5, 10,  8,  9,  9, 10, 10, 10,  7, 10,  5,  9,\n",
       "        10,  6,  5,  5, 10, 10, 10,  6, 10,  6, 10, 10, 10,  7,  5,  8,  5,\n",
       "         5, 10,  9,  9, 10,  9,  5, 10, 10, 10, 10,  9, 10, 10,  9,  9]))"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_floor[:50], y[700:][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./reviews/reviews_24.csv\n",
      "./reviews/reviews_25.csv\n",
      "./reviews/reviews_26.csv\n",
      "./reviews/reviews_27.csv\n",
      "./reviews/reviews_28.csv\n",
      "./reviews/reviews_29.csv\n",
      "./reviews/reviews_30.csv\n",
      "./reviews/reviews_31.csv\n",
      "./reviews/reviews_32.csv\n",
      "./reviews/reviews_33.csv\n",
      "./reviews/reviews_34.csv\n",
      "./reviews/reviews_35.csv\n",
      "./reviews/reviews_36.csv\n",
      "./reviews/reviews_37.csv\n",
      "./reviews/reviews_38.csv\n",
      "./reviews/reviews_39.csv\n",
      "./reviews/reviews_40.csv\n",
      "./reviews/reviews_41.csv\n",
      "./reviews/reviews_42.csv\n",
      "./reviews/reviews_43.csv\n",
      "./reviews/reviews_44.csv\n",
      "./reviews/reviews_45.csv\n",
      "./reviews/reviews_46.csv\n",
      "./reviews/reviews_47.csv\n",
      "./reviews/reviews_48.csv\n",
      "./reviews/reviews_49.csv\n",
      "./reviews/reviews_50.csv\n",
      "./reviews/reviews_51.csv\n",
      "./reviews/reviews_52.csv\n",
      "./reviews/reviews_53.csv\n",
      "./reviews/reviews_54.csv\n",
      "./reviews/reviews_55.csv\n",
      "./reviews/reviews_56.csv\n",
      "./reviews/reviews_57.csv\n",
      "./reviews/reviews_58.csv\n",
      "./reviews/reviews_59.csv\n",
      "./reviews/reviews_60.csv\n",
      "./reviews/reviews_61.csv\n",
      "./reviews/reviews_62.csv\n",
      "./reviews/reviews_63.csv\n",
      "./reviews/reviews_64.csv\n",
      "./reviews/reviews_65.csv\n",
      "./reviews/reviews_66.csv\n",
      "./reviews/reviews_67.csv\n",
      "./reviews/reviews_68.csv\n",
      "./reviews/reviews_69.csv\n",
      "./reviews/reviews_70.csv\n",
      "./reviews/reviews_71.csv\n",
      "./reviews/reviews_72.csv\n",
      "./reviews/reviews_73.csv\n",
      "./reviews/reviews_74.csv\n",
      "./reviews/reviews_75.csv\n",
      "./reviews/reviews_76.csv\n",
      "./reviews/reviews_77.csv\n",
      "./reviews/reviews_78.csv\n",
      "./reviews/reviews_79.csv\n",
      "./reviews/reviews_80.csv\n",
      "./reviews/reviews_81.csv\n",
      "./reviews/reviews_82.csv\n",
      "./reviews/reviews_83.csv\n",
      "./reviews/reviews_84.csv\n",
      "./reviews/reviews_85.csv\n",
      "./reviews/reviews_86.csv\n",
      "./reviews/reviews_87.csv\n",
      "./reviews/reviews_88.csv\n",
      "./reviews/reviews_89.csv\n",
      "./reviews/reviews_90.csv\n",
      "./reviews/reviews_91.csv\n",
      "./reviews/reviews_92.csv\n",
      "./reviews/reviews_93.csv\n",
      "./reviews/reviews_94.csv\n",
      "./reviews/reviews_95.csv\n",
      "./reviews/reviews_96.csv\n",
      "./reviews/reviews_97.csv\n",
      "./reviews/reviews_98.csv\n",
      "./reviews/reviews_99.csv\n",
      "./reviews/reviews_100.csv\n",
      "./reviews/reviews_101.csv\n",
      "./reviews/reviews_102.csv\n",
      "./reviews/reviews_103.csv\n",
      "./reviews/reviews_104.csv\n",
      "./reviews/reviews_105.csv\n",
      "./reviews/reviews_106.csv\n",
      "./reviews/reviews_107.csv\n",
      "./reviews/reviews_108.csv\n",
      "./reviews/reviews_109.csv\n",
      "./reviews/reviews_110.csv\n",
      "./reviews/reviews_111.csv\n",
      "./reviews/reviews_112.csv\n",
      "./reviews/reviews_113.csv\n",
      "./reviews/reviews_114.csv\n",
      "./reviews/reviews_115.csv\n",
      "./reviews/reviews_116.csv\n",
      "./reviews/reviews_117.csv\n",
      "./reviews/reviews_118.csv\n",
      "./reviews/reviews_119.csv\n",
      "./reviews/reviews_120.csv\n",
      "./reviews/reviews_121.csv\n",
      "./reviews/reviews_122.csv\n",
      "./reviews/reviews_123.csv\n",
      "./reviews/reviews_124.csv\n",
      "./reviews/reviews_125.csv\n",
      "./reviews/reviews_126.csv\n",
      "./reviews/reviews_127.csv\n",
      "./reviews/reviews_128.csv\n",
      "./reviews/reviews_129.csv\n",
      "./reviews/reviews_130.csv\n",
      "./reviews/reviews_131.csv\n",
      "./reviews/reviews_132.csv\n",
      "./reviews/reviews_133.csv\n",
      "./reviews/reviews_134.csv\n",
      "./reviews/reviews_135.csv\n",
      "./reviews/reviews_136.csv\n",
      "./reviews/reviews_137.csv\n",
      "./reviews/reviews_138.csv\n",
      "./reviews/reviews_139.csv\n",
      "./reviews/reviews_140.csv\n",
      "./reviews/reviews_141.csv\n",
      "./reviews/reviews_142.csv\n",
      "./reviews/reviews_143.csv\n",
      "./reviews/reviews_144.csv\n",
      "./reviews/reviews_145.csv\n",
      "./reviews/reviews_146.csv\n",
      "./reviews/reviews_147.csv\n",
      "./reviews/reviews_148.csv\n",
      "./reviews/reviews_149.csv\n",
      "./reviews/reviews_150.csv\n",
      "./reviews/reviews_151.csv\n",
      "./reviews/reviews_152.csv\n",
      "./reviews/reviews_153.csv\n",
      "./reviews/reviews_154.csv\n",
      "./reviews/reviews_155.csv\n",
      "./reviews/reviews_156.csv\n",
      "./reviews/reviews_157.csv\n",
      "./reviews/reviews_158.csv\n",
      "./reviews/reviews_159.csv\n",
      "./reviews/reviews_160.csv\n",
      "./reviews/reviews_161.csv\n",
      "./reviews/reviews_162.csv\n",
      "./reviews/reviews_163.csv\n",
      "./reviews/reviews_164.csv\n",
      "./reviews/reviews_165.csv\n",
      "./reviews/reviews_166.csv\n",
      "./reviews/reviews_167.csv\n",
      "./reviews/reviews_168.csv\n",
      "./reviews/reviews_169.csv\n",
      "./reviews/reviews_170.csv\n",
      "./reviews/reviews_171.csv\n",
      "./reviews/reviews_172.csv\n",
      "./reviews/reviews_173.csv\n",
      "./reviews/reviews_174.csv\n",
      "./reviews/reviews_175.csv\n",
      "./reviews/reviews_176.csv\n",
      "./reviews/reviews_177.csv\n",
      "./reviews/reviews_178.csv\n",
      "./reviews/reviews_179.csv\n",
      "./reviews/reviews_180.csv\n"
     ]
    }
   ],
   "source": [
    "imdb = pd.DataFrame(columns = ['review_id', 'rating', 'useful', 'useful_of', 'movie_name', 'movie_id', \n",
    "                               'numOfReviews', 'review_name', 'author', 'region', 'date', 'review_text'])\n",
    "\n",
    "#5, 23, 182\n",
    "for i in xrange(24,181):\n",
    "    cvs_name = './reviews/reviews_' + str(i) + '.csv'\n",
    "    print cvs_name\n",
    "    imdb1 = pd.read_csv(cvs_name)\n",
    "    imdb = imdb.append(imdb1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-4e1b38c958de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimdb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./reviews_5.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimdb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eugene/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eugene/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eugene/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    980\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/eugene/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1717\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1719\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1720\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read (pandas/_libs/parsers.c:10862)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory (pandas/_libs/parsers.c:11138)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows (pandas/_libs/parsers.c:11884)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows (pandas/_libs/parsers.c:11755)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error (pandas/_libs/parsers.c:28765)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n"
     ]
    }
   ],
   "source": [
    "imdb1 = pd.read_csv('./reviews_5.csv')\n",
    "imdb1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schindler's List 1375 ---------------\n",
      "0.0\n",
      "0.00727272727273\n",
      "0.0145454545455\n",
      "0.0218181818182\n",
      "0.0290909090909\n",
      "0.0363636363636\n",
      "0.0436363636364\n",
      "0.0509090909091\n",
      "0.0581818181818\n",
      "0.0654545454545\n",
      "0.0727272727273\n",
      "0.08\n",
      "0.0872727272727\n",
      "0.0945454545455\n",
      "0.101818181818\n",
      "0.109090909091\n",
      "0.116363636364\n",
      "0.123636363636\n",
      "0.130909090909\n",
      "0.138181818182\n",
      "0.145454545455\n",
      "0.152727272727\n",
      "0.16\n",
      "0.167272727273\n",
      "0.174545454545\n",
      "0.181818181818\n",
      "0.189090909091\n",
      "0.196363636364\n",
      "0.203636363636\n",
      "0.210909090909\n",
      "0.218181818182\n",
      "0.225454545455\n",
      "0.232727272727\n",
      "0.24\n",
      "0.247272727273\n",
      "0.254545454545\n",
      "0.261818181818\n",
      "0.269090909091\n",
      "0.276363636364\n",
      "0.283636363636\n",
      "0.290909090909\n",
      "0.298181818182\n",
      "0.305454545455\n",
      "0.312727272727\n",
      "0.32\n",
      "0.327272727273\n",
      "0.334545454545\n",
      "0.341818181818\n",
      "0.349090909091\n",
      "0.356363636364\n",
      "0.363636363636\n",
      "0.370909090909\n",
      "0.378181818182\n",
      "0.385454545455\n",
      "0.392727272727\n",
      "0.4\n",
      "0.407272727273\n",
      "0.414545454545\n",
      "0.421818181818\n",
      "0.429090909091\n",
      "0.436363636364\n",
      "0.443636363636\n",
      "0.450909090909\n",
      "0.458181818182\n",
      "0.465454545455\n",
      "0.472727272727\n",
      "0.48\n",
      "0.487272727273\n",
      "0.494545454545\n",
      "0.501818181818\n",
      "0.509090909091\n",
      "0.516363636364\n",
      "0.523636363636\n",
      "0.530909090909\n",
      "0.538181818182\n",
      "0.545454545455\n",
      "0.552727272727\n",
      "0.56\n",
      "0.567272727273\n",
      "0.574545454545\n",
      "0.581818181818\n",
      "0.589090909091\n",
      "0.596363636364\n",
      "0.603636363636\n",
      "0.610909090909\n",
      "0.618181818182\n",
      "0.625454545455\n",
      "0.632727272727\n",
      "0.64\n",
      "0.647272727273\n",
      "0.654545454545\n",
      "0.661818181818\n",
      "0.669090909091\n",
      "0.676363636364\n",
      "0.683636363636\n",
      "0.690909090909\n",
      "0.698181818182\n",
      "0.705454545455\n",
      "0.712727272727\n",
      "0.72\n",
      "0.727272727273\n",
      "0.734545454545\n",
      "0.741818181818\n",
      "0.749090909091\n",
      "0.756363636364\n",
      "0.763636363636\n",
      "0.770909090909\n",
      "0.778181818182\n",
      "0.785454545455\n",
      "0.792727272727\n",
      "0.8\n",
      "0.807272727273\n",
      "0.814545454545\n",
      "0.821818181818\n",
      "0.829090909091\n",
      "0.836363636364\n",
      "0.843636363636\n",
      "0.850909090909\n",
      "0.858181818182\n",
      "0.865454545455\n",
      "0.872727272727\n",
      "0.88\n",
      "0.887272727273\n",
      "0.894545454545\n",
      "0.901818181818\n",
      "0.909090909091\n",
      "0.916363636364\n",
      "0.923636363636\n",
      "0.930909090909\n",
      "0.938181818182\n",
      "0.945454545455\n",
      "0.952727272727\n",
      "0.96\n",
      "0.967272727273\n",
      "0.974545454545\n",
      "0.981818181818\n",
      "0.989090909091\n",
      "0.996363636364\n"
     ]
    }
   ],
   "source": [
    "df5 = ParseMovie('tt0108052')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
