{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,5)\n",
    "\n",
    "# Plotting config\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "reviews = pd.read_csv('stemmed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_id</th>\n",
       "      <th>date</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>movie_name</th>\n",
       "      <th>numOfReviews</th>\n",
       "      <th>rating</th>\n",
       "      <th>region</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_name</th>\n",
       "      <th>review_text</th>\n",
       "      <th>useful</th>\n",
       "      <th>useful_of</th>\n",
       "      <th>category</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>carflo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26 November 2003</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>4857</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>349418</td>\n",
       "      <td>Tied for the best movie I have ever seen</td>\n",
       "      <td>why do i want to write the 234th comment on t...</td>\n",
       "      <td>2275.0</td>\n",
       "      <td>2611.0</td>\n",
       "      <td>1</td>\n",
       "      <td>whi do i want to write the 234th comment on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wesley S. Walker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27 August 2002</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>4857</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Paducah, KY</td>\n",
       "      <td>349147</td>\n",
       "      <td>Shawshank Redeems Hollywood</td>\n",
       "      <td>can hollywood, usually creating things for e...</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>1712.0</td>\n",
       "      <td>1</td>\n",
       "      <td>can hollywood, usual creat thing for enterta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Justin M (kaspen12)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10 February 2006</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>4857</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Vancouver, Canada</td>\n",
       "      <td>1288098</td>\n",
       "      <td>A classic piece of unforgettable film-making.</td>\n",
       "      <td>in its oscar year, shawshank redemption (writ...</td>\n",
       "      <td>896.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1</td>\n",
       "      <td>in it oscar year, shawshank redempt (written ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Si Cole</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3 August 2001</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>4857</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>348829</td>\n",
       "      <td>The best story ever told on film</td>\n",
       "      <td>i believe that this film is the best story e...</td>\n",
       "      <td>891.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>1</td>\n",
       "      <td>i believ that thi film is the best stori eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thomas McFadden (tmac4)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25 July 2001</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>4857</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>348821</td>\n",
       "      <td>Powerful</td>\n",
       "      <td>one of my all time favorites. shawshank rede...</td>\n",
       "      <td>706.0</td>\n",
       "      <td>859.0</td>\n",
       "      <td>1</td>\n",
       "      <td>one of my all time favorites. shawshank rede...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    author author_id              date   movie_id  \\\n",
       "0                   carflo       NaN  26 November 2003  tt0111161   \n",
       "1         Wesley S. Walker       NaN    27 August 2002  tt0111161   \n",
       "2      Justin M (kaspen12)       NaN  10 February 2006  tt0111161   \n",
       "3                  Si Cole       NaN     3 August 2001  tt0111161   \n",
       "4  Thomas McFadden (tmac4)       NaN      25 July 2001  tt0111161   \n",
       "\n",
       "                 movie_name  numOfReviews  rating             region  \\\n",
       "0  The Shawshank Redemption          4857    10.0              Texas   \n",
       "1  The Shawshank Redemption          4857    10.0        Paducah, KY   \n",
       "2  The Shawshank Redemption          4857    10.0  Vancouver, Canada   \n",
       "3  The Shawshank Redemption          4857     8.0                NaN   \n",
       "4  The Shawshank Redemption          4857    10.0     Houston, Texas   \n",
       "\n",
       "   review_id                                    review_name  \\\n",
       "0     349418       Tied for the best movie I have ever seen   \n",
       "1     349147                    Shawshank Redeems Hollywood   \n",
       "2    1288098  A classic piece of unforgettable film-making.   \n",
       "3     348829               The best story ever told on film   \n",
       "4     348821                                       Powerful   \n",
       "\n",
       "                                         review_text  useful  useful_of  \\\n",
       "0   why do i want to write the 234th comment on t...  2275.0     2611.0   \n",
       "1    can hollywood, usually creating things for e...  1467.0     1712.0   \n",
       "2   in its oscar year, shawshank redemption (writ...   896.0     1015.0   \n",
       "3    i believe that this film is the best story e...   891.0     1205.0   \n",
       "4    one of my all time favorites. shawshank rede...   706.0      859.0   \n",
       "\n",
       "   category                                            stemmed  \n",
       "0         1   whi do i want to write the 234th comment on t...  \n",
       "1         1    can hollywood, usual creat thing for enterta...  \n",
       "2         1   in it oscar year, shawshank redempt (written ...  \n",
       "3         1    i believ that thi film is the best stori eve...  \n",
       "4         1    one of my all time favorites. shawshank rede...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(402356, 15)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0507337014552e-05, 7.265329845975008e-05, 6.415191172696946e-05, 6.89464975179261e-05, 5.0461724781753044e-05, 4.39734400422145e-05, 3.294458720432233e-05, 2.1918769041930604e-05, 1.607665348381081e-05, 6.89731280693042e-06]\n"
     ]
    }
   ],
   "source": [
    "S = np.argsort(reviews.rating.value_counts().index)\n",
    "ratingCounts = reviews.rating.value_counts().values[S]\n",
    "proba = map(lambda x: 1.0/x, ratingCounts)\n",
    "print proba\n",
    "row_proba = map(lambda x: proba[int(x)-1], reviews.rating)\n",
    "row_proba /= sum(row_proba)\n",
    "idx = (np.random.choice(reviews.index, size=100000, replace=False, p=row_proba))\n",
    "reviewsNormed = reviews.loc[idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_TRAIN_SLICE = slice(None, 90000)\n",
    "BIG_TEST_SLICE = slice(90000, 100000)\n",
    "SMALL_TRAIN_SLICE = slice(None, 9000)\n",
    "SMALL_TEST_SLICE = slice(9000, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = reviewsNormed.stemmed[SMALL_TRAIN_SLICE]\n",
    "y_train = reviewsNormed.rating[SMALL_TRAIN_SLICE]\n",
    "\n",
    "X_test = reviewsNormed.stemmed[SMALL_TEST_SLICE]\n",
    "y_test = reviewsNormed.rating[SMALL_TEST_SLICE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3 ,  0.45,  0.6 ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_df_range = np.linspace(0.001, 0.01, 3).round(3)\n",
    "max_df_range = np.linspace(0.3, 0.6, 3).round(2)\n",
    "ngram_range = [(1, 1), (1, 2), (1, 3)]\n",
    "stop_words_range = ['english', None]\n",
    "max_df_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinReg(LinearRegression):\n",
    "    def __init__(self, fit_intercept=True, normalize=False, copy_X=True, n_jobs=1):\n",
    "        super(MyLinReg, self).__init__(fit_intercept, normalize, copy_X, n_jobs)\n",
    "    def predict(self, X):\n",
    "        y_pred = super(MyLinReg, self).predict(X).round()\n",
    "        return map(lambda x: 10 if x > 10 else 1 if x < 1 else x, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), min_df=0.001, max_df=0.3)),\n",
    "                          ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                          ('clf', MyLinReg()),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.3, max_features=None, min_df=0.001,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "      ...      use_idf=True)), ('clf', MyLinReg(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg_text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linreg_text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.478"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            reviewsNormed.stemmed, reviewsNormed.rating, test_size=0.5, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "linreg_text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', MyLinReg()),\n",
    "])\n",
    "\n",
    "parameters = {'vect__ngram_range': [(1, 2)],\n",
    "           'vect__min_df' : min_df_range,\n",
    "           'vect__max_df' : max_df_range,\n",
    "           'vect__stop_words' : ['english'],\n",
    "           'tfidf__use_idf': (True, False),\n",
    "           'clf__normalize' : (True, False)\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(linreg_text_clf, parameters)\n",
    "gs_clf = gs_clf.fit(X_train, y_train)\n",
    "y_pred = gs_clf.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "gs_clf = gs_clf.fit(X_train, y_train)\n",
    "y_pred = gs_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "\n",
    "print \"accuracy:\", accuracy\n",
    "print \"MAE:\", mae\n",
    "print \"MSE:\", mse\n",
    "print confusion_matrix(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_parameters, score, _ = max(gs_clf.grid_scores_, key=lambda x: x[1])\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     knn_text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "#                          ('tfidf', TfidfTransformer()),\n",
    "#                          ('clf', KNeighborsClassifier()),\n",
    "#     ])\n",
    "\n",
    "#     parameters = {'vect__ngram_range': ngram_range,\n",
    "#                    'vect__min_df' : min_df_range,\n",
    "#                    'vect__max_df' : max_df_range,\n",
    "#                    'vect__stop_words' : stop_words_range,\n",
    "#                     'tfidf__use_idf': (True, False),\n",
    "#                    'clf__n_neighbors': [10, 20, 30, 40]\n",
    "#      }\n",
    "\n",
    "#     gs_clf = GridSearchCV(knn_text_clf, parameters, n_jobs=-1)\n",
    "\n",
    "#     %%time\n",
    "#     gs_clf = gs_clf.fit(X_train, y_train)\n",
    "\n",
    "#     y_pred = gs_clf.predict(X_test)\n",
    "# except:\n",
    "#     print 'Whoooops :('"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     best_parameters, score, _ = max(gs_clf.grid_scores_, key=lambda x: x[1])\n",
    "#     for param_name in sorted(parameters.keys()):\n",
    "#         print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "# except:\n",
    "#     print 'Whoops'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " best_nb_parameters = {'vect__ngram_range': (1, 2),\n",
    "               'vect__min_df' : 0.003,\n",
    "               'vect__max_df' : 0.6,\n",
    "               'vect__stop_words' : None,\n",
    "               'tfidf__use_idf': True,\n",
    "               'clf__n_neighbors' : 50 \n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_nb_text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), min_df=0.003, max_df=0.6)),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                     ('clf', KNeighborsClassifier(n_neighbors=50)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 1.37 s, total: 1min 3s\n",
      "Wall time: 1min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.6, max_features=None, min_df=0.003,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "      ...wski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=50, p=2,\n",
       "           weights='uniform'))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "best_nb_text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whooops\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    y_pred = best_nb_text_clf.predict(X_test)\n",
    "except:\n",
    "    print 'Whooops'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "    mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "    mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "\n",
    "    print \"accuracy:\", accuracy\n",
    "    print \"MAE:\", mae\n",
    "    print \"MSE:\", mse\n",
    "    print confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "except:\n",
    "    print 'Whoops'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# try:\n",
    "#     nb_text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "#                      ('clf', MultinomialNB()),\n",
    "#     ])\n",
    "    \n",
    "#     parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "#                'vect__min_df' : min_df_range,\n",
    "#                'vect__max_df' : max_df_range,\n",
    "#                'vect__stop_words' : stop_words_range,\n",
    "#                'tfidf__use_idf': (True, False),\n",
    "#                'clf__alpha' : [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "#     }\n",
    "    \n",
    "#     gs_clf = GridSearchCV(nb_text_clf, parameters)\n",
    "#     gs_clf = gs_clf.fit(X_train, y_train)\n",
    "#     y_pred = gs_clf.predict(X_test)\n",
    "# except:\n",
    "#     'Whoooops :('\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     best_parameters, score, _ = max(gs_clf.grid_scores_, key=lambda x: x[1])\n",
    "#     for param_name in sorted(parameters.keys()):\n",
    "#         print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "# except:\n",
    "#     print 'Whoops'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " best_bayes_parameters = {'vect__ngram_range': (1, 2),\n",
    "               'vect__min_df' : 0.001,\n",
    "               'vect__max_df' : 0.3,\n",
    "               'vect__stop_words' : None,\n",
    "               'tfidf__use_idf': True,\n",
    "               'clf__alpha' : 0.2\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_bayes_text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), min_df=0.001, max_df=0.3)),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                     ('clf', MultinomialNB(alpha=0.2)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 2.06 s, total: 1min 5s\n",
      "Wall time: 1min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.3, max_features=None, min_df=0.001,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "      ...False,\n",
       "         use_idf=True)), ('clf', MultinomialNB(alpha=0.2, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "best_bayes_text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_bayes_text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5165\n",
      "MAE: 1.1116\n",
      "MSE: 4.043\n",
      "[[812  30  27  29  48  38  19  24  10  34]\n",
      " [146 356  19  22  27  29  25  15   7  18]\n",
      " [116  12 396  28  45  59  45  27  10   9]\n",
      " [ 74  16  21 322  44  78  77  40  11  14]\n",
      " [ 66  13  13  36 396 109  82  66  17  27]\n",
      " [ 48  11  18  20  42 426 153 146  44  50]\n",
      " [ 32   9  19  10  48  86 441 237 104  72]\n",
      " [ 31   4  10   7  27  62 125 527 232 210]\n",
      " [ 34   7   6  10  24  29  66 215 519 379]\n",
      " [ 29   1   6   1  17  15  29 123 265 970]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "\n",
    "print \"accuracy:\", accuracy\n",
    "print \"MAE:\", mae\n",
    "print \"MSE:\", mse\n",
    "print confusion_matrix(y_pred=y_pred, y_true=y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.59      0.76      0.66      1071\n",
      "        2.0       0.78      0.54      0.63       664\n",
      "        3.0       0.74      0.53      0.62       747\n",
      "        4.0       0.66      0.46      0.54       697\n",
      "        5.0       0.55      0.48      0.51       825\n",
      "        6.0       0.46      0.44      0.45       958\n",
      "        7.0       0.42      0.42      0.42      1058\n",
      "        8.0       0.37      0.43      0.40      1235\n",
      "        9.0       0.43      0.40      0.41      1289\n",
      "       10.0       0.54      0.67      0.60      1456\n",
      "\n",
      "avg / total       0.53      0.52      0.52     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ненормированные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = reviews.stemmed[SMALL_TRAIN_SLICE]\n",
    "y_train = reviews.rating[SMALL_TRAIN_SLICE]\n",
    "\n",
    "X_test = reviews.stemmed[SMALL_TEST_SLICE]\n",
    "y_test = reviews.rating[SMALL_TEST_SLICE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.8 s, sys: 2.58 s, total: 14.4 s\n",
      "Wall time: 19min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.3, max_features=None, min_df=0.001,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "      ...False,\n",
       "         use_idf=True)), ('clf', MultinomialNB(alpha=0.2, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "best_bayes_text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_bayes_text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.794\n",
      "MAE: 0.495\n",
      "MSE: 2.025\n",
      "[[  0   0   0   0   0   0   1   0   9]\n",
      " [  0   0   0   0   0   0   0   0   7]\n",
      " [  0   0   0   0   0   0   0   0   3]\n",
      " [  1   0   0   0   0   0   1   0   3]\n",
      " [  0   0   0   0   0   0   1   0  10]\n",
      " [  0   0   0   0   0   0   3   0  22]\n",
      " [  0   0   0   0   0   0   4   0  46]\n",
      " [  0   0   0   0   0   0   7   2  76]\n",
      " [  0   0   0   0   0   0  16   0 788]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "\n",
    "print \"accuracy:\", accuracy\n",
    "print \"MAE:\", mae\n",
    "print \"MSE:\", mse\n",
    "print confusion_matrix(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.00      0.00      0.00        10\n",
      "        3.0       0.00      0.00      0.00         7\n",
      "        4.0       0.00      0.00      0.00         3\n",
      "        5.0       0.00      0.00      0.00         5\n",
      "        6.0       0.00      0.00      0.00        11\n",
      "        7.0       0.00      0.00      0.00        25\n",
      "        8.0       0.12      0.08      0.10        50\n",
      "        9.0       1.00      0.02      0.05        85\n",
      "       10.0       0.82      0.98      0.89       804\n",
      "\n",
      "avg / total       0.75      0.79      0.73      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кросс-валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = KFold(n_splits=4, random_state=123, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.50436\n",
      "MAE: 1.19072\n",
      "MSE: 4.41\n",
      "[[2066   45   89   58   56   80   72   65   32   89]\n",
      " [ 529 1264   69   79  104  116   83   82   38   48]\n",
      " [ 425   42 1120   63  125  206  132   95   42   35]\n",
      " [ 287   49   83 1099  140  301  240  146   56   66]\n",
      " [ 213   26   55   58 1190  271  335  200   85   74]\n",
      " [ 140   23   37   37  118 1065  453  368  102  117]\n",
      " [ 116   12   22   24   86  166 1010  613  283  248]\n",
      " [  83   16   16   12   67   69  298 1049  464  445]\n",
      " [  52    7    5   10   26   32  133  474 1034  776]\n",
      " [  65    5    6    4   22   27   51  247  430 1712]]\n",
      "accuracy: 0.50716\n",
      "MAE: 1.16696\n",
      "MSE: 4.29216\n",
      "[[1971   49   79   51   80   71   60   57   46   75]\n",
      " [ 452 1179   99   45  102  113  115   50   36   53]\n",
      " [ 408   39 1191   76  116  142  139   88   51   40]\n",
      " [ 281   49   68  983  129  230  222  139   37   56]\n",
      " [ 197   32   62   48 1087  262  330  177   62   67]\n",
      " [ 132   26   48   58  112 1075  454  315  136  113]\n",
      " [  92   11   26   20   98  213 1113  567  269  235]\n",
      " [  79   10   14   13   88  118  294 1088  595  442]\n",
      " [  73    9   13    9   42   53  161  428 1108  801]\n",
      " [  58    6    7    4   18   34   59  223  565 1884]]\n",
      "accuracy: 0.51\n",
      "MAE: 1.13132\n",
      "MSE: 4.11036\n",
      "[[2064   65   92   57   88   95   63   47   35   58]\n",
      " [ 423 1007   75   58   82   91   73   46   24   33]\n",
      " [ 345   60 1068   97  105  150  129   52   36   56]\n",
      " [ 249   45   82  932  116  184  176  123   33   52]\n",
      " [ 190   43   59   68 1057  284  298  190   75   76]\n",
      " [ 138   24   28   52  123 1117  427  302   94   88]\n",
      " [ 100   29   24   35  100  226 1068  589  220  211]\n",
      " [  69   14   27   18   83  110  366 1161  555  433]\n",
      " [  62   18    9   11   36   61  167  496 1200  911]\n",
      " [  83    4   18    8   35   26   74  287  581 2076]]\n",
      "accuracy: 0.505\n",
      "MAE: 1.1254\n",
      "MSE: 4.05012\n",
      "[[2063   96   91   71   84   75   64   57   31   78]\n",
      " [ 371  934   67   61   71   66   72   39   12   42]\n",
      " [ 329   56  966   81  120  133  146   75   19   39]\n",
      " [ 206   40   60  830  119  154  211   95   34   50]\n",
      " [ 176   37   49   70 1032  218  310  176   37   47]\n",
      " [ 123   29   36   61  138 1020  487  304  100   89]\n",
      " [  97   15   34   50  121  177 1060  590  208  214]\n",
      " [  76   13   34   21   95   89  399 1204  538  450]\n",
      " [  54   11   13   10   55   73  227  612 1274  982]\n",
      " [  84   12    9   13   22   33   94  356  592 2242]]\n",
      "CPU times: user 4min 23s, sys: 6.48 s, total: 4min 30s\n",
      "Wall time: 10min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for train_index, test_index in gkf.split(reviewsNormed):\n",
    "    X_train, y_train = reviewsNormed.iloc[train_index].stemmed, reviewsNormed.iloc[train_index].rating\n",
    "    X_test, y_test = reviewsNormed.iloc[test_index].stemmed, reviewsNormed.iloc[test_index].rating\n",
    "    \n",
    "    best_bayes_text_clf.fit(X_train, y_train)\n",
    "    y_pred = best_bayes_text_clf.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "    mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "    mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "\n",
    "    print \"accuracy:\", accuracy\n",
    "    print \"MAE:\", mae\n",
    "    print \"MSE:\", mse\n",
    "    print confusion_matrix(y_pred=y_pred, y_true=y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10h 22min 21s, sys: 3min 55s, total: 10h 26min 16s\n",
      "Wall time: 10h 26min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "try:\n",
    "    bayes_text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "    ])\n",
    "    \n",
    "    parameters = {'vect__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "               'vect__min_df' : min_df_range,\n",
    "               'vect__max_df' : max_df_range,\n",
    "               'vect__stop_words' : stop_words_range,\n",
    "               'tfidf__use_idf': (True, False),\n",
    "               'clf__alpha' : [0.1, 0.2, 0.4],\n",
    "                'clf__fit_prior' : [True, False]\n",
    "    }\n",
    "    \n",
    "    gs_clf = GridSearchCV(bayes_text_clf, parameters)\n",
    "    gs_clf = gs_clf.fit(X_train, y_train)\n",
    "    y_pred = gs_clf.predict(X_test)\n",
    "except:\n",
    "    'Whoooops :('"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.365\n",
      "MAE: 1.407\n",
      "MSE: 4.601\n",
      "[[52 10 16  5  8  8  5  2  1  2]\n",
      " [15 29  6  8  6  5  2  0  3  3]\n",
      " [15  6 33  5  7  6  8  2  0  2]\n",
      " [11  6 10 32 13 14 13  2  1  0]\n",
      " [ 4  5  5 11 41 16 13  4  0  2]\n",
      " [ 3  5  8  5  6 26 29 14  3  2]\n",
      " [ 1  2  5  7  8 16 35 26  5  9]\n",
      " [ 3  0  1  1  6  4 24 34 12 16]\n",
      " [ 1  1  3  3  2  4 14 17 27 26]\n",
      " [ 0  0  1  1  2  1 12 18 22 56]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.50      0.48      0.49       109\n",
      "        2.0       0.45      0.38      0.41        77\n",
      "        3.0       0.38      0.39      0.38        84\n",
      "        4.0       0.41      0.31      0.36       102\n",
      "        5.0       0.41      0.41      0.41       101\n",
      "        6.0       0.26      0.26      0.26       101\n",
      "        7.0       0.23      0.31      0.26       114\n",
      "        8.0       0.29      0.34      0.31       101\n",
      "        9.0       0.36      0.28      0.31        98\n",
      "       10.0       0.47      0.50      0.48       113\n",
      "\n",
      "avg / total       0.37      0.36      0.37      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "\n",
    "print \"accuracy:\", accuracy\n",
    "print \"MAE:\", mae\n",
    "print \"MSE:\", mse\n",
    "print confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__alpha: 0.2\n",
      "clf__fit_prior: False\n",
      "tfidf__use_idf: True\n",
      "vect__max_df: 0.29999999999999999\n",
      "vect__min_df: 0.001\n",
      "vect__ngram_range: (1, 2)\n",
      "vect__stop_words: None\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    best_parameters, score, _ = max(gs_clf.grid_scores_, key=lambda x: x[1])\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "except:\n",
    "    print 'Whoops'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# try:\n",
    "#     forest_text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "#                      ('clf', RandomForestClassifier()),\n",
    "#     ])\n",
    "    \n",
    "#     parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "#                'vect__min_df' : min_df_range,\n",
    "#                'vect__max_df' : max_df_range,\n",
    "#                'vect__stop_words' : stop_words_range,\n",
    "#                'tfidf__use_idf': (True, False),\n",
    "#                'clf__n_estimators' : [10, 20, 30]\n",
    "#     }\n",
    "    \n",
    "#     gs_clf = GridSearchCV(forest_text_clf, parameters)\n",
    "#     gs_clf = gs_clf.fit(X_train, y_train)\n",
    "#     y_pred = gs_clf.predict(X_test)\n",
    "# except:\n",
    "#     'Whoooops :('"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     best_parameters, score, _ = max(gs_clf.grid_scores_, key=lambda x: x[1])\n",
    "#     for param_name in sorted(parameters.keys()):\n",
    "#         print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "# except:\n",
    "#     print 'Whoops'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " best_forest_parameters = {'vect__ngram_range': (1, 2),\n",
    "               'vect__min_df' : 0.003,\n",
    "               'vect__max_df' : 0.3,\n",
    "               'vect__stop_words' :'english',\n",
    "               'tfidf__use_idf': False,\n",
    "               'clf__n_estimators' : 30\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_forest_text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), min_df=0.003, max_df=0.3, stop_words='english')),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                     ('clf', RandomForestClassifier(n_estimators=30)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 52s, sys: 1.47 s, total: 4min 53s\n",
      "Wall time: 5min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "try:\n",
    "    best_forest_text_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    y_pred = best_forest_text_clf.predict(X_test)\n",
    "except:\n",
    "    print 'Whoooops'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5415\n",
      "MAE: 1.2248\n",
      "MSE: 5.0344\n",
      "[[833  18  21  21  27  23  32  21  18  48]\n",
      " [142 392  10  15  19  17  19  16  13  20]\n",
      " [120  21 388  27  28  35  29  30  25  42]\n",
      " [ 85  18  17 374  32  27  54  34  26  38]\n",
      " [ 96  11  16  18 450  48  71  58  51  68]\n",
      " [ 65  12  22  27  37 456 111 100  64  90]\n",
      " [ 47  15  11  23  26  68 447 161 121 140]\n",
      " [ 43   8  10  15  19  55 122 535 157 240]\n",
      " [ 34   8   5   8  14  26 106 135 585 354]\n",
      " [ 39   3  10  11   6  17  63 120 192 955]]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "    mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "    mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "\n",
    "    print \"accuracy:\", accuracy\n",
    "    print \"MAE:\", mae\n",
    "    print \"MSE:\", mse\n",
    "    print confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "except:\n",
    "    print 'Whoops'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "               'vect__min_df' : min_df_range,\n",
    "               'vect__max_df' : max_df_range,\n",
    "               'vect__stop_words' : stop_words_range,\n",
    "               'tfidf__use_idf': (True, False),\n",
    "               'clf__loss' : ['hinge', 'log'], \n",
    "               'clf__penalty' : ['l2', 'l1'],\n",
    "               'clf__random_state' : [123]\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs_clf = GridSearchCV(svm_text_clf, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# gs_clf = gs_clf.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = gs_clf.predict(X_test)\n",
    "\n",
    "# best_parameters, score, _ = max(gs_clf.grid_scores_, key=lambda x: x[1])\n",
    "# for param_name in sorted(parameters.keys()):\n",
    "#     print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "# best_parameters, score, _ = max(gs_clf.grid_scores_, key=lambda x: x[1])\n",
    "# for param_name in sorted(parameters.keys()):\n",
    "#     print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    " best_svm_parameters = {'vect__ngram_range': (1, 2),\n",
    "               'vect__min_df' : 0.01,\n",
    "               'vect__max_df' : 0.3,\n",
    "               'vect__stop_words' : None,\n",
    "               'tfidf__use_idf': True,\n",
    "               'clf__loss' : 'log', \n",
    "               'clf__penalty' : 'l2',\n",
    "               'clf__random_state' : [123]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "best_svm_text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), min_df=0.01, max_df=0.3)),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                     ('clf', SGDClassifier(loss='log', penalty='l2', random_state=123)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 13s, sys: 2.42 s, total: 1min 15s\n",
      "Wall time: 3min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "try:\n",
    "    best_svm_text_clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = best_svm_text_clf.predict(X_test)\n",
    "except:\n",
    "    print 'Whoops'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[769,  48,  39,  30,  35,  31,  27,  19,  12,  52],\n",
       "       [225, 232,  44,  25,  34,  38,  26,  15,   7,  17],\n",
       "       [206,  54, 223,  49,  59,  42,  35,  30,  19,  28],\n",
       "       [138,  27,  42, 173,  80,  84,  62,  39,  20,  40],\n",
       "       [116,  38,  39,  38, 268, 124, 122,  69,  30,  43],\n",
       "       [ 76,  27,  34,  30,  82, 322, 195, 122,  42,  54],\n",
       "       [ 57,  11,  10,  19,  45, 127, 366, 203, 124,  97],\n",
       "       [ 46,   6,   9,  14,  30,  64, 168, 414, 198, 255],\n",
       "       [ 30,   4,  10,   2,  18,  27,  85, 231, 358, 510],\n",
       "       [ 27,   4,   8,   3,   7,  13,  28, 109, 225, 992]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.4117\n",
      "MAE: 1.3635\n",
      "MSE: 5.0123\n",
      "[[769  48  39  30  35  31  27  19  12  52]\n",
      " [225 232  44  25  34  38  26  15   7  17]\n",
      " [206  54 223  49  59  42  35  30  19  28]\n",
      " [138  27  42 173  80  84  62  39  20  40]\n",
      " [116  38  39  38 268 124 122  69  30  43]\n",
      " [ 76  27  34  30  82 322 195 122  42  54]\n",
      " [ 57  11  10  19  45 127 366 203 124  97]\n",
      " [ 46   6   9  14  30  64 168 414 198 255]\n",
      " [ 30   4  10   2  18  27  85 231 358 510]\n",
      " [ 27   4   8   3   7  13  28 109 225 992]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "\n",
    "print \"accuracy:\", accuracy\n",
    "print \"MAE:\", mae\n",
    "print \"MSE:\", mse\n",
    "print confusion_matrix(y_pred=y_pred, y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
