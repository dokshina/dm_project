{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,5)\n",
    "\n",
    "# Plotting config\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "reviews = pd.read_csv('stemmed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0507337014552e-05, 7.265329845975008e-05, 6.415191172696946e-05, 6.89464975179261e-05, 5.0461724781753044e-05, 4.39734400422145e-05, 3.294458720432233e-05, 2.1918769041930604e-05, 1.607665348381081e-05, 6.89731280693042e-06]\n"
     ]
    }
   ],
   "source": [
    "S = np.argsort(reviews.rating.value_counts().index)\n",
    "ratingCounts = reviews.rating.value_counts().values[S]\n",
    "proba = map(lambda x: 1.0/x, ratingCounts)\n",
    "print proba\n",
    "row_proba = map(lambda x: proba[int(x)-1], reviews.rating)\n",
    "row_proba /= sum(row_proba)\n",
    "idx = (np.random.choice(reviews.index, size=100000, replace=False, p=row_proba))\n",
    "reviewsNormed = reviews.loc[idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewsNormed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## учим на нормированной, тестим на обычной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_idx(y_train):\n",
    "    S = np.argsort(y_train.value_counts().index)\n",
    "    ratingCounts = y_train.value_counts().values[S]\n",
    "    proba = map(lambda x: 1.0/x, ratingCounts)\n",
    "    row_proba = map(lambda x: proba[int(x)-1], y_train)\n",
    "    row_proba /= sum(row_proba)\n",
    "    idx = (np.random.choice(y_train.index, size=100000, replace=False, p=row_proba))\n",
    "    return idx   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit done\n",
      "predict done\n",
      "accuracy: 0.276203163368\n",
      "MAE: 1.35378619929\n",
      "MSE: 3.39691218722\n",
      "[[ 1752  2079  1828  1203   699   380   152    43     9     6]\n",
      " [  362   821  1090   602   314   166    64    19     4     0]\n",
      " [  153   415  1179  1131   547   289   107    29     6     2]\n",
      " [  130   173   563  1279   827   384   163    65    13     7]\n",
      " [   60   160   360  1160  1650   952   466   139    40    11]\n",
      " [   30    92   204   538  1346  1734   984   476   135    65]\n",
      " [    2    26    83   337   995  1721  2160  1432   589   250]\n",
      " [    2    11    55   176   629  1504  2902  3055  1957  1090]\n",
      " [    6     6    26   134   472  1233  2709  4346  3868  2890]\n",
      " [    6    12    50   229   788  2273  5100  8183  9340 10285]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.70      0.21      0.33      8151\n",
      "        2.0       0.22      0.24      0.23      3442\n",
      "        3.0       0.22      0.31      0.25      3858\n",
      "        4.0       0.19      0.35      0.25      3604\n",
      "        5.0       0.20      0.33      0.25      4998\n",
      "        6.0       0.16      0.31      0.21      5604\n",
      "        7.0       0.15      0.28      0.19      7595\n",
      "        8.0       0.17      0.27      0.21     11381\n",
      "        9.0       0.24      0.25      0.24     15690\n",
      "       10.0       0.70      0.28      0.40     36266\n",
      "\n",
      "avg / total       0.42      0.28      0.30    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "accuracy: 0.281800196841\n",
      "MAE: 1.34138921751\n",
      "MSE: 3.354830051\n",
      "[[ 1832  2059  1775  1277   671   318   135    43     9     6]\n",
      " [  302   902  1103   584   284   162    72    30     7     1]\n",
      " [  218   467  1249  1121   491   247   102    30     8     2]\n",
      " [   96   218   555  1243   932   393   147    45    17    10]\n",
      " [   67   153   423  1059  1662  1018   383   145    44    11]\n",
      " [   26    78   231   612  1365  1762  1079   427   155    43]\n",
      " [    5    24   116   372   900  1745  2169  1331   619   280]\n",
      " [    5    15    49   200   585  1606  2780  3168  1997  1102]\n",
      " [    1    10    39   127   412  1210  2668  4190  3846  2960]\n",
      " [    4    11    43   230   773  2259  5006  8252  9061 10513]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.72      0.23      0.34      8125\n",
      "        2.0       0.23      0.26      0.24      3447\n",
      "        3.0       0.22      0.32      0.26      3935\n",
      "        4.0       0.18      0.34      0.24      3656\n",
      "        5.0       0.21      0.33      0.25      4965\n",
      "        6.0       0.16      0.30      0.21      5778\n",
      "        7.0       0.15      0.29      0.20      7561\n",
      "        8.0       0.18      0.28      0.22     11507\n",
      "        9.0       0.24      0.25      0.25     15463\n",
      "       10.0       0.70      0.29      0.41     36152\n",
      "\n",
      "avg / total       0.42      0.28      0.31    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "accuracy: 0.283062760342\n",
      "MAE: 1.32833610037\n",
      "MSE: 3.2963644136\n",
      "[[ 1908  2115  1857  1205   685   336   130    43    19     6]\n",
      " [  330   835  1169   561   314   144    66    22     6     1]\n",
      " [  190   420  1189  1067   528   237   112    48     7     1]\n",
      " [  112   193   629  1242   822   372   178    68    11     2]\n",
      " [   54   146   402  1068  1648   992   422   144    33    16]\n",
      " [   31    75   244   586  1385  1770   989   418   145    49]\n",
      " [    5    25    87   335   854  1727  2114  1530   660   241]\n",
      " [    7     8    39   170   531  1660  2706  3097  2139  1082]\n",
      " [    0    10    21   122   397  1207  2722  4267  3942  2897]\n",
      " [    4     8    39   229   772  2153  4867  8204  9186 10728]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.72      0.23      0.35      8304\n",
      "        2.0       0.22      0.24      0.23      3448\n",
      "        3.0       0.21      0.31      0.25      3799\n",
      "        4.0       0.19      0.34      0.24      3629\n",
      "        5.0       0.21      0.33      0.26      4925\n",
      "        6.0       0.17      0.31      0.22      5692\n",
      "        7.0       0.15      0.28      0.19      7578\n",
      "        8.0       0.17      0.27      0.21     11439\n",
      "        9.0       0.24      0.25      0.25     15585\n",
      "       10.0       0.71      0.30      0.42     36190\n",
      "\n",
      "avg / total       0.43      0.28      0.31    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "accuracy: 0.281144061478\n",
      "MAE: 1.35209615365\n",
      "MSE: 3.40643609142\n",
      "[[ 1823  2004  1927  1174   720   354   130    42    21     4]\n",
      " [  306   848  1071   599   341   175    61    19     6     1]\n",
      " [  191   432  1274  1134   558   251   106    36    12     2]\n",
      " [   97   191   576  1298   813   404   160    63    10     3]\n",
      " [   62   132   374  1073  1675  1005   415   148    33    12]\n",
      " [   26    83   224   601  1381  1755   970   448   144    35]\n",
      " [    9    19    95   320   960  1834  2144  1342   634   263]\n",
      " [    1    12    40   224   614  1524  2749  3120  2004  1008]\n",
      " [    1     3    28   122   438  1291  2827  4197  3827  2730]\n",
      " [   18    12    56   239   816  2197  5276  8148  9098 10516]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.72      0.22      0.34      8199\n",
      "        2.0       0.23      0.25      0.24      3427\n",
      "        3.0       0.22      0.32      0.26      3996\n",
      "        4.0       0.19      0.36      0.25      3615\n",
      "        5.0       0.20      0.34      0.25      4929\n",
      "        6.0       0.16      0.31      0.21      5667\n",
      "        7.0       0.14      0.28      0.19      7620\n",
      "        8.0       0.18      0.28      0.22     11296\n",
      "        9.0       0.24      0.25      0.24     15464\n",
      "       10.0       0.72      0.29      0.41     36376\n",
      "\n",
      "avg / total       0.43      0.28      0.31    100589\n",
      "\n",
      "====================\n",
      "CPU times: user 13min 46s, sys: 6.77 s, total: 13min 53s\n",
      "Wall time: 14min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "linreg_accuracy_list = []\n",
    "linreg_mae_list = []\n",
    "linreg_mse_list = []\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "for train, test in kf.split(reviews):\n",
    "    X_train = reviews.review_text[train]\n",
    "    y_train = reviews.rating[train]\n",
    "    \n",
    "    X_test = reviews.review_text[test]\n",
    "    y_test = reviews.rating[test]\n",
    "    \n",
    "    idx = norm_idx(y_train)\n",
    "    X_train = X_train[idx]\n",
    "    y_train = y_train[idx]\n",
    "    \n",
    "    linreg_text_clf_best_mae = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), max_df=0.4, min_df=0.003)),\n",
    "                          ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                          ('clf', LinearRegression()),\n",
    "                    ])\n",
    "    linreg_text_clf_best_mae.fit(X_train, y_train)\n",
    "    print 'fit done'\n",
    "    \n",
    "    y_pred = linreg_text_clf_best_mae.predict(X_test).round()\n",
    "    y_pred = map(lambda x: 10 if x > 10 else 1 if x < 1 else x, y_pred)\n",
    "    print 'predict done'\n",
    "    \n",
    "    accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "    mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "    mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "    \n",
    "    linreg_accuracy_list += [accuracy]\n",
    "    linreg_mae_list += [mae]\n",
    "    linreg_mse_list += [mse]\n",
    "\n",
    "    print \"accuracy:\", accuracy\n",
    "    print \"MAE:\", mae\n",
    "    print \"MSE:\", mse\n",
    "    print confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "    print classification_report(y_test, y_pred)\n",
    "    \n",
    "    print('='*20)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy 0.280552545507\n",
      "mean MAE 1.3439019177\n",
      "mean MSE 3.36363568581\n"
     ]
    }
   ],
   "source": [
    "print 'mean accuracy', np.mean(linreg_accuracy_list)\n",
    "print 'mean MAE', np.mean(linreg_mae_list)\n",
    "print 'mean MSE', np.mean(linreg_mse_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit done\n",
      "predict done\n",
      "[ 10.  10.  10. ...,   8.   1.   1.]\n",
      "accuracy: 0.555468291762\n",
      "MAE: 0.982393701101\n",
      "MSE: 3.73434470966\n",
      "[[ 6542   166   229   169   231   211   206   187    99   229]\n",
      " [  774  1766   122    96   133   171   142   101    44    73]\n",
      " [  698    59  1924   135   203   299   227   185    53    75]\n",
      " [  462    52    84  1705   234   392   347   255    76    84]\n",
      " [  454    68   101   102  2376   536   660   476   124   172]\n",
      " [  301    42    62    95   277  2491  1066   809   217   249]\n",
      " [  291    32    65    72   279   527  3147  1914   725   578]\n",
      " [  358    55    96    77   292   366  1174  5033  2004  1946]\n",
      " [  339    44    56    49   204   260   687  2744  6106  4864]\n",
      " [  865    59    79    95   297   258   616  3179  6055 24784]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.59      0.79      0.68      8269\n",
      "        2.0       0.75      0.52      0.61      3422\n",
      "        3.0       0.68      0.50      0.58      3858\n",
      "        4.0       0.66      0.46      0.54      3691\n",
      "        5.0       0.52      0.47      0.50      5069\n",
      "        6.0       0.45      0.44      0.45      5609\n",
      "        7.0       0.38      0.41      0.40      7630\n",
      "        8.0       0.34      0.44      0.38     11401\n",
      "        9.0       0.39      0.40      0.40     15353\n",
      "       10.0       0.75      0.68      0.71     36287\n",
      "\n",
      "avg / total       0.57      0.56      0.56    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "[ 10.   9.  10. ...,   1.   1.   5.]\n",
      "accuracy: 0.556273548798\n",
      "MAE: 0.973486166479\n",
      "MSE: 3.67312529203\n",
      "[[ 6527   112   181   138   215   262   191   166   100   223]\n",
      " [  751  1830   102    95   119   190   146   103    43    86]\n",
      " [  744    75  1938   134   197   315   250   145    63    84]\n",
      " [  445    56   109  1633   241   407   339   237    70    86]\n",
      " [  468    49    95   104  2295   566   616   415   127   151]\n",
      " [  329    46    95    85   218  2551  1060   788   237   255]\n",
      " [  278    43    62    52   260   621  3159  1775   744   607]\n",
      " [  344    53    66    81   266   339  1292  4968  1977  1954]\n",
      " [  343    26    45    20   213   264   718  2854  6353  4769]\n",
      " [  857    35    95    58   263   260   742  3130  6204 24701]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.59      0.80      0.68      8115\n",
      "        2.0       0.79      0.53      0.63      3465\n",
      "        3.0       0.70      0.49      0.58      3945\n",
      "        4.0       0.68      0.45      0.54      3623\n",
      "        5.0       0.54      0.47      0.50      4886\n",
      "        6.0       0.44      0.45      0.45      5664\n",
      "        7.0       0.37      0.42      0.39      7601\n",
      "        8.0       0.34      0.44      0.38     11340\n",
      "        9.0       0.40      0.41      0.40     15605\n",
      "       10.0       0.75      0.68      0.71     36345\n",
      "\n",
      "avg / total       0.58      0.56      0.56    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "[ 10.  10.  10. ...,   9.   8.  10.]\n",
      "accuracy: 0.552575331299\n",
      "MAE: 0.977989641014\n",
      "MSE: 3.65450496575\n",
      "[[ 6452   117   220   176   223   206   229   197    93   229]\n",
      " [  773  1803   108   120   148   143   124   130    37    82]\n",
      " [  729    70  1944   163   183   264   271   153    45    85]\n",
      " [  459    63   115  1645   185   341   390   236    60   104]\n",
      " [  440    62    87   150  2354   493   691   390   121   133]\n",
      " [  333    34    96   112   262  2427  1082   880   233   266]\n",
      " [  308    44    81    81   305   472  3145  1789   716   640]\n",
      " [  329    61    76    63   288   397  1390  4845  2058  1987]\n",
      " [  295    41    69    36   219   221   798  2724  6658  4678]\n",
      " [  794    67    83    71   252   231   640  3252  6314 24310]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.59      0.79      0.68      8142\n",
      "        2.0       0.76      0.52      0.62      3468\n",
      "        3.0       0.68      0.50      0.57      3907\n",
      "        4.0       0.63      0.46      0.53      3598\n",
      "        5.0       0.53      0.48      0.50      4921\n",
      "        6.0       0.47      0.42      0.44      5725\n",
      "        7.0       0.36      0.41      0.38      7581\n",
      "        8.0       0.33      0.42      0.37     11494\n",
      "        9.0       0.41      0.42      0.42     15739\n",
      "       10.0       0.75      0.68      0.71     36014\n",
      "\n",
      "avg / total       0.57      0.55      0.56    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "[  9.  10.  10. ...,   9.   3.   2.]\n",
      "accuracy: 0.555995188341\n",
      "MAE: 0.973555756594\n",
      "MSE: 3.66448617642\n",
      "[[ 6548   129   197   160   226   246   188   224    94   241]\n",
      " [  769  1774   103   104   137   160   123   122    46    71]\n",
      " [  706    77  1997   115   208   238   229   175    66    67]\n",
      " [  512    66    99  1573   225   344   385   222    72    94]\n",
      " [  432    45   105    95  2338   495   671   457   147   156]\n",
      " [  324    35    64   103   266  2498  1090   881   230   252]\n",
      " [  309    28    73    45   286   431  3194  1866   695   615]\n",
      " [  332    37    56    65   269   326  1252  4904  2130  2017]\n",
      " [  364    28    38    33   176   230   712  2895  6255  4774]\n",
      " [  810    38    84    77   252   260   704  3255  6012 24846]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.59      0.79      0.68      8253\n",
      "        2.0       0.79      0.52      0.63      3409\n",
      "        3.0       0.71      0.51      0.60      3878\n",
      "        4.0       0.66      0.44      0.53      3592\n",
      "        5.0       0.53      0.47      0.50      4941\n",
      "        6.0       0.48      0.43      0.46      5743\n",
      "        7.0       0.37      0.42      0.40      7542\n",
      "        8.0       0.33      0.43      0.37     11388\n",
      "        9.0       0.40      0.40      0.40     15505\n",
      "       10.0       0.75      0.68      0.72     36338\n",
      "\n",
      "avg / total       0.58      0.56      0.56    100589\n",
      "\n",
      "====================\n",
      "CPU times: user 7min 48s, sys: 3.82 s, total: 7min 51s\n",
      "Wall time: 7min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bayes_accuracy_list = []\n",
    "bayes_mae_list = []\n",
    "bayes_mse_list = []\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "for train, test in kf.split(reviews):\n",
    "    X_train = reviews.review_text[train]\n",
    "    y_train = reviews.rating[train]\n",
    "    \n",
    "    X_test = reviews.review_text[test]\n",
    "    y_test = reviews.rating[test]\n",
    "    \n",
    "    idx = norm_idx(y_train)\n",
    "    X_train = X_train[idx]\n",
    "    y_train = y_train[idx]\n",
    "    \n",
    "    bayes_text_clf_best_mae = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), max_df=0.3, min_df=0.001)),\n",
    "                          ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                          ('clf', MultinomialNB(alpha=0.2))\n",
    "                    ])\n",
    "    bayes_text_clf_best_mae.fit(X_train, y_train)\n",
    "    print 'fit done'\n",
    "    \n",
    "    y_pred = bayes_text_clf_best_mae.predict(X_test)\n",
    "    print 'predict done'\n",
    "    print y_pred\n",
    "    \n",
    "    accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "    mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "    mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "                           \n",
    "    bayes_accuracy_list += [accuracy]\n",
    "    bayes_mae_list += [mae]\n",
    "    bayes_mse_list += [mse]\n",
    "\n",
    "    print \"accuracy:\", accuracy\n",
    "    print \"MAE:\", mae\n",
    "    print \"MSE:\", mse\n",
    "    print confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "    print classification_report(y_test, y_pred)\n",
    "    \n",
    "    print('='*20)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy 0.55507809005\n",
      "mean MAE 0.976856316297\n",
      "mean MSE 3.68161528597\n"
     ]
    }
   ],
   "source": [
    "print 'mean accuracy', np.mean(bayes_accuracy_list)\n",
    "print 'mean MAE', np.mean(bayes_mae_list)\n",
    "print 'mean MSE', np.mean(bayes_mse_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit done\n",
      "predict done\n",
      "accuracy: 0.555667120659\n",
      "MAE: 0.944646034855\n",
      "MSE: 3.37477258945\n",
      "[[ 5986   549   519   356   265   185   102    61    60   162]\n",
      " [  551  1937   265   222   154   107    56    34    18    38]\n",
      " [  482   260  2200   314   259   200    95    48    32    48]\n",
      " [  239   193   258  1886   279   313   195    86    26    59]\n",
      " [  293   207   280   376  2454   580   398   158    88    94]\n",
      " [  177   141   221   341   400  2762   846   441   183   163]\n",
      " [  166   138   160   264   392   907  3391  1298   591   423]\n",
      " [  177   134   135   153   332   639  1771  4686  1825  1539]\n",
      " [  221   133   126   145   201   428  1199  2579  6102  4431]\n",
      " [  653   236   230   203   292   429  1177  3030  5461 24490]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.67      0.73      0.70      8245\n",
      "        2.0       0.49      0.57      0.53      3382\n",
      "        3.0       0.50      0.56      0.53      3938\n",
      "        4.0       0.44      0.53      0.48      3534\n",
      "        5.0       0.49      0.50      0.49      4928\n",
      "        6.0       0.42      0.49      0.45      5675\n",
      "        7.0       0.37      0.44      0.40      7730\n",
      "        8.0       0.38      0.41      0.39     11391\n",
      "        9.0       0.42      0.39      0.41     15565\n",
      "       10.0       0.78      0.68      0.72     36201\n",
      "\n",
      "avg / total       0.57      0.56      0.56    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "accuracy: 0.561085208124\n",
      "MAE: 0.933292904791\n",
      "MSE: 3.33454950342\n",
      "[[ 6128   601   435   353   227   161    91    46    38   145]\n",
      " [  545  2057   253   215   133   100    68    40    33    63]\n",
      " [  463   275  2152   281   241   175   101    52    24    45]\n",
      " [  329   216   269  1892   303   329   187    69    63    30]\n",
      " [  303   198   270   364  2435   598   405   149    93    93]\n",
      " [  189   160   244   322   425  2820   844   365   182   142]\n",
      " [  200   117   153   213   392   862  3479  1161   608   407]\n",
      " [  186   130   129   175   304   655  1697  4599  1975  1575]\n",
      " [  220   124   154   160   225   425  1075  2454  6308  4321]\n",
      " [  623   237   223   224   298   468  1107  2926  5602 24569]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.67      0.75      0.70      8225\n",
      "        2.0       0.50      0.59      0.54      3507\n",
      "        3.0       0.50      0.56      0.53      3809\n",
      "        4.0       0.45      0.51      0.48      3687\n",
      "        5.0       0.49      0.50      0.49      4908\n",
      "        6.0       0.43      0.50      0.46      5693\n",
      "        7.0       0.38      0.46      0.42      7592\n",
      "        8.0       0.39      0.40      0.40     11425\n",
      "        9.0       0.42      0.41      0.42     15466\n",
      "       10.0       0.78      0.68      0.73     36277\n",
      "\n",
      "avg / total       0.58      0.56      0.57    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "accuracy: 0.556840211156\n",
      "MAE: 0.936086450805\n",
      "MSE: 3.30501347066\n",
      "[[ 5956   520   531   403   268   180   109    47    55   143]\n",
      " [  512  2030   253   218   135   131    61    20    17    33]\n",
      " [  455   268  2215   320   236   183   107    53    26    43]\n",
      " [  301   218   278  1914   301   301   166    89    31    41]\n",
      " [  283   221   317   418  2451   562   406   168    75    84]\n",
      " [  142   155   243   335   464  2751   866   415   171   167]\n",
      " [  187   134   163   260   372   820  3411  1174   577   471]\n",
      " [  198   121   103   178   299   644  1793  4672  1918  1569]\n",
      " [  187   135   126   152   230   357  1173  2487  6458  4321]\n",
      " [  624   239   216   231   332   399  1096  3070  5676 24154]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.67      0.73      0.70      8212\n",
      "        2.0       0.50      0.60      0.54      3410\n",
      "        3.0       0.50      0.57      0.53      3906\n",
      "        4.0       0.43      0.53      0.47      3640\n",
      "        5.0       0.48      0.49      0.49      4985\n",
      "        6.0       0.43      0.48      0.46      5709\n",
      "        7.0       0.37      0.45      0.41      7569\n",
      "        8.0       0.38      0.41      0.39     11495\n",
      "        9.0       0.43      0.41      0.42     15626\n",
      "       10.0       0.78      0.67      0.72     36037\n",
      "\n",
      "avg / total       0.57      0.56      0.56    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "accuracy: 0.559643698615\n",
      "MAE: 0.93654375727\n",
      "MSE: 3.33322729125\n",
      "[[ 5922   560   475   343   273   173    92    69    61   129]\n",
      " [  536  2091   239   216   141    91    57    41    19    34]\n",
      " [  501   269  2156   293   272   189   115    52    40    48]\n",
      " [  306   211   284  1879   315   303   169    88    40    48]\n",
      " [  292   219   298   347  2604   508   362   185    88    93]\n",
      " [  190   180   228   324   481  2689   817   415   175   165]\n",
      " [  162   128   155   210   382   826  3500  1123   590   387]\n",
      " [  225   110   159   200   283   575  1678  4539  1877  1666]\n",
      " [  218   121   146   127   218   445  1123  2418  6178  4551]\n",
      " [  629   228   210   214   294   414  1139  3003  5602 24736]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.66      0.73      0.69      8097\n",
      "        2.0       0.51      0.60      0.55      3465\n",
      "        3.0       0.50      0.55      0.52      3935\n",
      "        4.0       0.45      0.52      0.48      3643\n",
      "        5.0       0.49      0.52      0.51      4996\n",
      "        6.0       0.43      0.47      0.45      5664\n",
      "        7.0       0.39      0.47      0.42      7463\n",
      "        8.0       0.38      0.40      0.39     11312\n",
      "        9.0       0.42      0.40      0.41     15545\n",
      "       10.0       0.78      0.68      0.72     36469\n",
      "\n",
      "avg / total       0.57      0.56      0.56    100589\n",
      "\n",
      "====================\n",
      "CPU times: user 14min 13s, sys: 5.81 s, total: 14min 19s\n",
      "Wall time: 14min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logreg_accuracy_list = []\n",
    "logreg_mae_list = []\n",
    "logreg_mse_list = []\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "for train, test in kf.split(reviews):\n",
    "    X_train = reviews.review_text[train]\n",
    "    y_train = reviews.rating[train]\n",
    "    \n",
    "    X_test = reviews.review_text[test]\n",
    "    y_test = reviews.rating[test]\n",
    "    \n",
    "    idx = norm_idx(y_train)\n",
    "    X_train = X_train[idx]\n",
    "    y_train = y_train[idx]\n",
    "    \n",
    "    logreg_text_clf = Pipeline([('vect', CountVectorizer(max_df=0.3, min_df=0.001, ngram_range=(1, 2))),\n",
    "                          ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                          ('clf', LogisticRegression(class_weight='balanced', penalty='l2')),\n",
    "                    ])\n",
    "    logreg_text_clf.fit(X_train, y_train)\n",
    "    print 'fit done'\n",
    "    \n",
    "    y_pred = logreg_text_clf.predict(X_test)\n",
    "    print 'predict done'\n",
    "    \n",
    "    accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "    mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "    mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "                           \n",
    "    logreg_accuracy_list += [accuracy]\n",
    "    logreg_mae_list += [mae]\n",
    "    logreg_mse_list += [mse]\n",
    "\n",
    "    print \"accuracy:\", accuracy\n",
    "    print \"MAE:\", mae\n",
    "    print \"MSE:\", mse\n",
    "    print confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "    print classification_report(y_test, y_pred)\n",
    "    \n",
    "    print('='*20)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy 0.558309059639\n",
      "mean MAE 0.93764228693\n",
      "mean MSE 3.3368907137\n"
     ]
    }
   ],
   "source": [
    "print 'mean accuracy', np.mean(logreg_accuracy_list)\n",
    "print 'mean MAE', np.mean(logreg_mae_list)\n",
    "print 'mean MSE', np.mean(logreg_mse_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## учим на обычной, тестим на обычной"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit done\n",
      "predict done\n",
      "accuracy: 0.321864219746\n",
      "MAE: 1.19596576166\n",
      "MSE: 2.87674596626\n",
      "[[ 1531  1490  1703  1385   944   591   298   117    32    16]\n",
      " [  374   531   758   815   498   286   131    58    13     6]\n",
      " [  229   362   777  1018   730   412   247    67    26     5]\n",
      " [  114   215   560   801   840   563   341   131    35     7]\n",
      " [   67   113   371   868  1222  1155   647   283    85    27]\n",
      " [   24    66   167   488  1194  1688  1139   694   248    98]\n",
      " [    6    16    81   255   622  1488  2111  1636   979   405]\n",
      " [    3     4    33   101   348  1006  2289  3308  2617  1723]\n",
      " [    0     3     9    47   189   615  1888  3882  4883  3959]\n",
      " [    5     6    11    44   220   765  2624  6207 10976 15524]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.65      0.19      0.29      8107\n",
      "        2.0       0.19      0.15      0.17      3470\n",
      "        3.0       0.17      0.20      0.19      3873\n",
      "        4.0       0.14      0.22      0.17      3607\n",
      "        5.0       0.18      0.25      0.21      4838\n",
      "        6.0       0.20      0.29      0.23      5806\n",
      "        7.0       0.18      0.28      0.22      7599\n",
      "        8.0       0.20      0.29      0.24     11432\n",
      "        9.0       0.25      0.32      0.28     15475\n",
      "       10.0       0.71      0.43      0.53     36382\n",
      "\n",
      "avg / total       0.42      0.32      0.35    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "accuracy: 0.32146656195\n",
      "MAE: 1.18959329549\n",
      "MSE: 2.83394804601\n",
      "[[ 1529  1566  1714  1456   941   552   277   124    32    15]\n",
      " [  351   534   819   653   586   286   122    48    15     3]\n",
      " [  218   370   819   959   773   441   205    80    26     4]\n",
      " [   94   219   496   910   855   576   308   129    35    11]\n",
      " [   70   139   420   945  1254  1145   647   305    95    28]\n",
      " [   25    63   182   516  1150  1481  1176   667   249    95]\n",
      " [    7    20    65   241   630  1431  2067  1794   948   419]\n",
      " [    1     6    17    89   338  1003  2321  3269  2606  1695]\n",
      " [    3     0     6    34   182   631  1866  3903  4808  4177]\n",
      " [    1     4    14    33   197   803  2337  6461 10694 15665]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.67      0.19      0.29      8206\n",
      "        2.0       0.18      0.16      0.17      3417\n",
      "        3.0       0.18      0.21      0.19      3895\n",
      "        4.0       0.16      0.25      0.19      3633\n",
      "        5.0       0.18      0.25      0.21      5048\n",
      "        6.0       0.18      0.26      0.21      5604\n",
      "        7.0       0.18      0.27      0.22      7622\n",
      "        8.0       0.19      0.29      0.23     11345\n",
      "        9.0       0.25      0.31      0.27     15610\n",
      "       10.0       0.71      0.43      0.54     36209\n",
      "\n",
      "avg / total       0.42      0.32      0.34    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "accuracy: 0.319339092744\n",
      "MAE: 1.20003181262\n",
      "MSE: 2.88262136019\n",
      "[[ 1498  1520  1708  1451  1011   589   263   119    36    15]\n",
      " [  351   479   730   778   562   266   156    64    19     3]\n",
      " [  217   359   807  1016   802   432   199    82    25     6]\n",
      " [  110   214   511   819   831   630   293   108    46     4]\n",
      " [   60   142   432   838  1304  1233   615   283    84    24]\n",
      " [   27    71   219   493  1087  1626  1219   654   221    95]\n",
      " [    4     9    74   232   677  1383  2072  1733   968   428]\n",
      " [    4     1    23    79   324  1096  2329  3245  2612  1678]\n",
      " [    3     2     5    43   186   592  1871  3948  4775  4144]\n",
      " [    2     7    15    49   241   761  2541  6264 10816 15497]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.66      0.18      0.29      8210\n",
      "        2.0       0.17      0.14      0.15      3408\n",
      "        3.0       0.18      0.20      0.19      3945\n",
      "        4.0       0.14      0.23      0.17      3566\n",
      "        5.0       0.19      0.26      0.22      5015\n",
      "        6.0       0.19      0.28      0.23      5712\n",
      "        7.0       0.18      0.27      0.22      7580\n",
      "        8.0       0.20      0.28      0.23     11391\n",
      "        9.0       0.24      0.31      0.27     15569\n",
      "       10.0       0.71      0.43      0.53     36193\n",
      "\n",
      "avg / total       0.42      0.32      0.34    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "accuracy: 0.324339639523\n",
      "MAE: 1.18700851982\n",
      "MSE: 2.84021115629\n",
      "[[ 1461  1620  1667  1514   939   604   287   108    43    13]\n",
      " [  320   529   761   825   517   284   156    56    18     3]\n",
      " [  203   426   757   980   831   397   189    71    17     4]\n",
      " [   90   189   540   901   916   615   315    91    31    10]\n",
      " [   42   161   400   854  1347  1159   608   251    76    18]\n",
      " [   34    66   220   471  1128  1528  1156   668   250    98]\n",
      " [    5    14    73   241   709  1342  2099  1744   890   436]\n",
      " [    2     2    34    90   336  1006  2238  3397  2672  1678]\n",
      " [    1     3    12    34   174   599  1834  3817  4960  4114]\n",
      " [    0     7    10    50   220   738  2445  6307 10777 15646]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.68      0.18      0.28      8256\n",
      "        2.0       0.18      0.15      0.16      3469\n",
      "        3.0       0.17      0.20      0.18      3875\n",
      "        4.0       0.15      0.24      0.19      3698\n",
      "        5.0       0.19      0.27      0.22      4916\n",
      "        6.0       0.18      0.27      0.22      5619\n",
      "        7.0       0.19      0.28      0.22      7553\n",
      "        8.0       0.21      0.30      0.24     11455\n",
      "        9.0       0.25      0.32      0.28     15548\n",
      "       10.0       0.71      0.43      0.54     36200\n",
      "\n",
      "avg / total       0.43      0.32      0.35    100589\n",
      "\n",
      "====================\n",
      "CPU times: user 13min, sys: 3.81 s, total: 13min 4s\n",
      "Wall time: 13min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "linreg2_accuracy_list = []\n",
    "linreg2_mae_list = []\n",
    "linreg2_mse_list = []\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "for train, test in kf.split(reviews):\n",
    "    X_train = reviews.review_text[train]\n",
    "    y_train = reviews.rating[train]\n",
    "    \n",
    "    X_test = reviews.review_text[test]\n",
    "    y_test = reviews.rating[test]\n",
    "    \n",
    "    idx = np.random.choice(y_train.index, size=100000, replace=False)\n",
    "    X_train = X_train[idx]\n",
    "    y_train = y_train[idx]\n",
    "    \n",
    "    linreg2_text_clf_best_mae = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), max_df=0.4, min_df=0.003)),\n",
    "                          ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                          ('clf', LinearRegression()),\n",
    "                    ])\n",
    "    linreg2_text_clf_best_mae.fit(X_train, y_train)\n",
    "    print 'fit done'\n",
    "    \n",
    "    y_pred = linreg2_text_clf_best_mae.predict(X_test).round()\n",
    "    y_pred = map(lambda x: 10 if x > 10 else 1 if x < 1 else x, y_pred)\n",
    "    print 'predict done'\n",
    "    \n",
    "    accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "    mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "    mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "    \n",
    "    linreg2_accuracy_list += [accuracy]\n",
    "    linreg2_mae_list += [mae]\n",
    "    linreg2_mse_list += [mse]\n",
    "\n",
    "    print \"accuracy:\", accuracy\n",
    "    print \"MAE:\", mae\n",
    "    print \"MSE:\", mse\n",
    "    print confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "    print classification_report(y_test, y_pred)\n",
    "    \n",
    "    print('='*20)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy 0.321752378491\n",
      "mean MAE 1.1931498474\n",
      "mean MSE 2.85838163219\n"
     ]
    }
   ],
   "source": [
    "print 'mean accuracy', np.mean(linreg2_accuracy_list)\n",
    "print 'mean MAE', np.mean(linreg2_mae_list)\n",
    "print 'mean MSE', np.mean(linreg2_mse_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit done\n",
      "predict done\n",
      "[ 10.  10.  10. ...,   9.  10.  10.]\n",
      "accuracy: 0.554513913052\n",
      "MAE: 1.1301335136\n",
      "MSE: 4.77293739872\n",
      "[[ 6393    16    41    39    73    83   107   191    71  1219]\n",
      " [ 1116  1242    39    22    69    73    94   103    43   521]\n",
      " [ 1068    14  1421    31   113   140   184   189    81   750]\n",
      " [  739    25    31  1141   133   235   283   265    92   689]\n",
      " [  644     7    24    34  1771   323   499   491   160  1050]\n",
      " [  455     3    22    18   135  1790   695   838   324  1470]\n",
      " [  343     1    20     8   106   198  1957  1403   676  2825]\n",
      " [  241     3     7     6    80    83   399  3237  1412  5979]\n",
      " [  123     2     1     2    28    55   146  1171  3632 10374]\n",
      " [  267     0     0     0    30    21   106   876  1645 33194]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.56      0.78      0.65      8233\n",
      "        2.0       0.95      0.37      0.54      3322\n",
      "        3.0       0.88      0.36      0.51      3991\n",
      "        4.0       0.88      0.31      0.46      3633\n",
      "        5.0       0.70      0.35      0.47      5003\n",
      "        6.0       0.60      0.31      0.41      5750\n",
      "        7.0       0.44      0.26      0.33      7537\n",
      "        8.0       0.37      0.28      0.32     11447\n",
      "        9.0       0.45      0.23      0.31     15534\n",
      "       10.0       0.57      0.92      0.70     36139\n",
      "\n",
      "avg / total       0.56      0.55      0.52    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "[ 10.  10.  10. ...,  10.   1.   1.]\n",
      "accuracy: 0.554464205828\n",
      "MAE: 1.14173517979\n",
      "MSE: 4.86329519132\n",
      "[[ 6345     6    37    25    88    86    96   161    91  1260]\n",
      " [ 1082  1284    31    26   105    78   102   118    59   560]\n",
      " [ 1036     5  1401    39    95   123   216   209    77   751]\n",
      " [  754    13    28  1229   122   185   264   301    84   723]\n",
      " [  629     2    16    29  1818   241   475   472   166  1067]\n",
      " [  423     8    19    25   129  1775   654   923   253  1483]\n",
      " [  317     0     4    13    96   164  1884  1518   629  2938]\n",
      " [  237     2     2     2    76    82   377  3218  1188  6219]\n",
      " [  162     5     0     2    24    61   138  1120  3366 10678]\n",
      " [  246     3     0     0    39    14    87   853  1470 33453]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.56      0.77      0.65      8195\n",
      "        2.0       0.97      0.37      0.54      3445\n",
      "        3.0       0.91      0.35      0.51      3952\n",
      "        4.0       0.88      0.33      0.48      3703\n",
      "        5.0       0.70      0.37      0.48      4915\n",
      "        6.0       0.63      0.31      0.42      5692\n",
      "        7.0       0.44      0.25      0.32      7563\n",
      "        8.0       0.36      0.28      0.32     11403\n",
      "        9.0       0.46      0.22      0.29     15556\n",
      "       10.0       0.57      0.93      0.70     36165\n",
      "\n",
      "avg / total       0.57      0.55      0.51    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "[ 10.  10.  10. ...,   9.  10.   1.]\n",
      "accuracy: 0.555368877313\n",
      "MAE: 1.12532185428\n",
      "MSE: 4.73937508077\n",
      "[[ 6347    22    25    28    74   130   129   163    93  1209]\n",
      " [ 1141  1311    22    31    79    91   107   113    68   556]\n",
      " [  979    12  1399    34    84   162   206   185    79   619]\n",
      " [  755    23    25  1126   118   210   305   279    93   658]\n",
      " [  623     1    16    17  1684   300   522   480   171  1122]\n",
      " [  409    12    15    22   115  1765   742   854   297  1427]\n",
      " [  327     6     4     8   105   217  1965  1420   687  2866]\n",
      " [  220     3     1     0    68    96   456  3145  1276  5990]\n",
      " [  160     0     0     1    32    68   171  1063  3542 10656]\n",
      " [  243     0     1     2    16    32    72   854  1552 33580]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.57      0.77      0.65      8220\n",
      "        2.0       0.94      0.37      0.53      3519\n",
      "        3.0       0.93      0.37      0.53      3759\n",
      "        4.0       0.89      0.31      0.46      3592\n",
      "        5.0       0.71      0.34      0.46      4936\n",
      "        6.0       0.57      0.31      0.40      5658\n",
      "        7.0       0.42      0.26      0.32      7605\n",
      "        8.0       0.37      0.28      0.32     11255\n",
      "        9.0       0.45      0.23      0.30     15693\n",
      "       10.0       0.57      0.92      0.71     36352\n",
      "\n",
      "avg / total       0.56      0.56      0.52    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "[ 10.  10.  10. ...,  10.   5.   1.]\n",
      "accuracy: 0.55601507123\n",
      "MAE: 1.12653471055\n",
      "MSE: 4.75104633707\n",
      "[[ 6337    10    27    19    85    85   105   170    74  1219]\n",
      " [ 1168  1272    31    16    75   105   109   120    64   518]\n",
      " [ 1046     8  1427    17   134   161   182   165    56   690]\n",
      " [  769    18    30  1078   109   230   281   297   109   655]\n",
      " [  641     8    15    15  1808   258   456   542   172  1048]\n",
      " [  428     1    13     5   123  1792   621   927   313  1418]\n",
      " [  309     3    10     1   104   201  1944  1507   712  2858]\n",
      " [  252     1     6     9    87    87   374  3340  1380  5982]\n",
      " [  173     0     7     1    30    65   137  1037  3604 10365]\n",
      " [  254     0     0     0    39    27    76   862  1743 33327]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.56      0.78      0.65      8131\n",
      "        2.0       0.96      0.37      0.53      3478\n",
      "        3.0       0.91      0.37      0.52      3886\n",
      "        4.0       0.93      0.30      0.46      3576\n",
      "        5.0       0.70      0.36      0.48      4963\n",
      "        6.0       0.60      0.32      0.41      5641\n",
      "        7.0       0.45      0.25      0.33      7649\n",
      "        8.0       0.37      0.29      0.33     11518\n",
      "        9.0       0.44      0.23      0.30     15419\n",
      "       10.0       0.57      0.92      0.71     36328\n",
      "\n",
      "avg / total       0.57      0.56      0.52    100589\n",
      "\n",
      "====================\n",
      "CPU times: user 7min 42s, sys: 4.86 s, total: 7min 46s\n",
      "Wall time: 7min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bayes2_accuracy_list = []\n",
    "bayes2_mae_list = []\n",
    "bayes2_mse_list = []\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "for train, test in kf.split(reviews):\n",
    "    X_train = reviews.review_text[train]\n",
    "    y_train = reviews.rating[train]\n",
    "    \n",
    "    X_test = reviews.review_text[test]\n",
    "    y_test = reviews.rating[test]\n",
    "    \n",
    "    idx = np.random.choice(y_train.index, size=100000, replace=False)\n",
    "    X_train = X_train[idx]\n",
    "    y_train = y_train[idx]\n",
    "    \n",
    "    bayes2_text_clf_best_mae = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), max_df=0.3, min_df=0.001)),\n",
    "                          ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                          ('clf', MultinomialNB(alpha=0.2))\n",
    "                    ])\n",
    "    bayes2_text_clf_best_mae.fit(X_train, y_train)\n",
    "    print 'fit done'\n",
    "    \n",
    "    y_pred = bayes2_text_clf_best_mae.predict(X_test)\n",
    "    print 'predict done'\n",
    "    print y_pred\n",
    "    \n",
    "    accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "    mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "    mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "                           \n",
    "    bayes2_accuracy_list += [accuracy]\n",
    "    bayes2_mae_list += [mae]\n",
    "    bayes2_mse_list += [mse]\n",
    "\n",
    "    print \"accuracy:\", accuracy\n",
    "    print \"MAE:\", mae\n",
    "    print \"MSE:\", mse\n",
    "    print confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "    print classification_report(y_test, y_pred)\n",
    "    \n",
    "    print('='*20)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy 0.555090516856\n",
      "mean MAE 1.13093131456\n",
      "mean MSE 4.78166350197\n"
     ]
    }
   ],
   "source": [
    "print 'mean accuracy', np.mean(bayes2_accuracy_list)\n",
    "print 'mean MAE', np.mean(bayes2_mae_list)\n",
    "print 'mean MSE', np.mean(bayes2_mse_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit done\n",
      "predict done\n",
      "accuracy: 0.574993289525\n",
      "MAE: 0.915070236308\n",
      "MSE: 3.24486772908\n",
      "[[ 5986   459   412   369   275   198   112    47    40   249]\n",
      " [  714  1807   236   223   177   101    58    33    17    73]\n",
      " [  633   211  1935   308   277   212   109    60    25    60]\n",
      " [  348   189   275  1620   347   335   201    78    22   103]\n",
      " [  356   179   312   383  2356   563   415   201    80   166]\n",
      " [  201   132   256   325   487  2606   844   458   144   245]\n",
      " [  205    96   141   204   429   846  3305  1145   549   673]\n",
      " [  164   110   131   183   279   600  1606  4310  1534  2355]\n",
      " [  204    98   153   158   226   412   994  2022  5197  6178]\n",
      " [  434   208   190   210   278   362   855  2083  3103 28716]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.65      0.73      0.69      8147\n",
      "        2.0       0.52      0.53      0.52      3439\n",
      "        3.0       0.48      0.51      0.49      3830\n",
      "        4.0       0.41      0.46      0.43      3518\n",
      "        5.0       0.46      0.47      0.46      5011\n",
      "        6.0       0.42      0.46      0.44      5698\n",
      "        7.0       0.39      0.44      0.41      7593\n",
      "        8.0       0.41      0.38      0.40     11272\n",
      "        9.0       0.49      0.33      0.39     15642\n",
      "       10.0       0.74      0.79      0.76     36439\n",
      "\n",
      "avg / total       0.57      0.57      0.57    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "accuracy: 0.572497986857\n",
      "MAE: 0.923480698685\n",
      "MSE: 3.27914583106\n",
      "[[ 6105   430   488   319   257   230   117    50    34   224]\n",
      " [  762  1738   233   225   168   119    67    41    18    62]\n",
      " [  657   252  1928   265   276   243   153    49    26    84]\n",
      " [  447   181   263  1677   337   347   189    93    31    83]\n",
      " [  330   203   275   323  2303   597   439   194    70   159]\n",
      " [  209   128   247   291   495  2553   858   464   158   227]\n",
      " [  203   120   158   231   377   820  3215  1206   518   698]\n",
      " [  242   104   135   175   268   619  1639  4375  1541  2414]\n",
      " [  194   116   125   116   187   438   979  2116  5168  6070]\n",
      " [  481   190   173   194   238   381   831  2259  2959 28525]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.63      0.74      0.68      8254\n",
      "        2.0       0.50      0.51      0.50      3433\n",
      "        3.0       0.48      0.49      0.48      3933\n",
      "        4.0       0.44      0.46      0.45      3648\n",
      "        5.0       0.47      0.47      0.47      4893\n",
      "        6.0       0.40      0.45      0.43      5630\n",
      "        7.0       0.38      0.43      0.40      7546\n",
      "        8.0       0.40      0.38      0.39     11512\n",
      "        9.0       0.49      0.33      0.40     15509\n",
      "       10.0       0.74      0.79      0.76     36231\n",
      "\n",
      "avg / total       0.57      0.57      0.57    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "accuracy: 0.574675163288\n",
      "MAE: 0.933412202129\n",
      "MSE: 3.37184980465\n",
      "[[ 6175   440   388   329   274   171   107    54    27   223]\n",
      " [  682  1800   241   198   187   144    58    39    16    86]\n",
      " [  676   226  1959   250   267   223   150    49    36    72]\n",
      " [  398   171   227  1712   327   358   241   114    36    90]\n",
      " [  411   179   285   329  2354   585   392   177    75   160]\n",
      " [  258   143   209   312   470  2494   886   455   155   288]\n",
      " [  203   109   135   217   402   820  3186  1273   550   723]\n",
      " [  224   108   118   197   294   528  1516  4448  1479  2523]\n",
      " [  218   110   121   143   234   360  1009  2084  5249  6075]\n",
      " [  519   197   200   201   279   380   865  2108  2917 28429]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.63      0.75      0.69      8188\n",
      "        2.0       0.52      0.52      0.52      3451\n",
      "        3.0       0.50      0.50      0.50      3908\n",
      "        4.0       0.44      0.47      0.45      3674\n",
      "        5.0       0.46      0.48      0.47      4947\n",
      "        6.0       0.41      0.44      0.43      5670\n",
      "        7.0       0.38      0.42      0.40      7618\n",
      "        8.0       0.41      0.39      0.40     11435\n",
      "        9.0       0.50      0.34      0.40     15603\n",
      "       10.0       0.74      0.79      0.76     36095\n",
      "\n",
      "avg / total       0.57      0.57      0.57    100589\n",
      "\n",
      "====================\n",
      "fit done\n",
      "predict done\n",
      "accuracy: 0.576454681923\n",
      "MAE: 0.917028700951\n",
      "MSE: 3.27150085993\n",
      "[[ 6194   418   421   285   301   173    91    43    44   220]\n",
      " [  702  1787   243   222   172   134    60    34    14    73]\n",
      " [  552   235  2025   301   280   229   111    68    36    80]\n",
      " [  399   185   264  1746   346   345   172    71    41    95]\n",
      " [  351   206   296   361  2285   621   423   181    71   171]\n",
      " [  215   121   237   337   491  2621   822   449   170   280]\n",
      " [  232   109   157   238   415   790  3211  1205   541   699]\n",
      " [  204    91   142   199   264   631  1546  4322  1508  2497]\n",
      " [  193   111   108   125   215   335   978  1958  5271  6154]\n",
      " [  496   190   171   207   298   348   869  2034  3083 28523]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.65      0.76      0.70      8190\n",
      "        2.0       0.52      0.52      0.52      3441\n",
      "        3.0       0.50      0.52      0.51      3917\n",
      "        4.0       0.43      0.48      0.45      3664\n",
      "        5.0       0.45      0.46      0.46      4966\n",
      "        6.0       0.42      0.46      0.44      5743\n",
      "        7.0       0.39      0.42      0.40      7597\n",
      "        8.0       0.42      0.38      0.40     11404\n",
      "        9.0       0.49      0.34      0.40     15448\n",
      "       10.0       0.74      0.79      0.76     36219\n",
      "\n",
      "avg / total       0.57      0.58      0.57    100589\n",
      "\n",
      "====================\n",
      "CPU times: user 13min 17s, sys: 4.61 s, total: 13min 22s\n",
      "Wall time: 13min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logreg2_accuracy_list = []\n",
    "logreg2_mae_list = []\n",
    "logreg2_mse_list = []\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "for train, test in kf.split(reviews):\n",
    "    X_train = reviews.review_text[train]\n",
    "    y_train = reviews.rating[train]\n",
    "    \n",
    "    X_test = reviews.review_text[test]\n",
    "    y_test = reviews.rating[test]\n",
    "    \n",
    "    idx = np.random.choice(y_train.index, size=100000, replace=False)\n",
    "    X_train = X_train[idx]\n",
    "    y_train = y_train[idx]\n",
    "    \n",
    "    logreg2_text_clf = Pipeline([('vect', CountVectorizer(max_df=0.3, min_df=0.001, ngram_range=(1, 2))),\n",
    "                          ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                          ('clf', LogisticRegression(class_weight='balanced', penalty='l2')),\n",
    "                    ])\n",
    "    logreg2_text_clf.fit(X_train, y_train)\n",
    "    print 'fit done'\n",
    "    \n",
    "    y_pred = logreg2_text_clf.predict(X_test)\n",
    "    print 'predict done'\n",
    "    \n",
    "    accuracy = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "    mae = mean_absolute_error(y_pred=y_pred, y_true=y_test)\n",
    "    mse = mean_squared_error(y_pred=y_pred, y_true=y_test)\n",
    "                           \n",
    "    logreg2_accuracy_list += [accuracy]\n",
    "    logreg2_mae_list += [mae]\n",
    "    logreg2_mse_list += [mse]\n",
    "\n",
    "    print \"accuracy:\", accuracy\n",
    "    print \"MAE:\", mae\n",
    "    print \"MSE:\", mse\n",
    "    print confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "    print classification_report(y_test, y_pred)\n",
    "    \n",
    "    print('='*20)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy 0.574655280398\n",
      "mean MAE 0.922247959518\n",
      "mean MSE 3.29184105618\n"
     ]
    }
   ],
   "source": [
    "print 'mean accuracy', np.mean(logreg2_accuracy_list)\n",
    "print 'mean MAE', np.mean(logreg2_mae_list)\n",
    "print 'mean MSE', np.mean(logreg2_mse_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравним"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LinearRegression\n",
      "  normed train\n",
      "    mean accuracy 0.280552545507\n",
      "    mean MAE 1.3439019177\n",
      "    mean MSE 3.36363568581\n",
      "  not normed train\n",
      "    mean accuracy 0.321752378491\n",
      "    mean MAE 1.1931498474\n",
      "    mean MSE 2.85838163219\n",
      "MultinomialNB\n",
      "  normed train\n",
      "    mean accuracy 0.55507809005\n",
      "    mean MAE 0.976856316297\n",
      "    mean MSE 3.68161528597\n",
      "  not normed train\n",
      "    mean accuracy 0.555090516856\n",
      "    mean MAE 1.13093131456\n",
      "    mean MSE 4.78166350197\n",
      "LogisticRegression\n",
      "  normed train\n",
      "    mean accuracy 0.558309059639\n",
      "    mean MAE 0.93764228693\n",
      "    mean MSE 3.3368907137\n",
      "  not normed train\n",
      "    mean accuracy 0.574655280398\n",
      "    mean MAE 0.922247959518\n",
      "    mean MSE 3.29184105618\n"
     ]
    }
   ],
   "source": [
    "print 'LinearRegression'\n",
    "print '  normed train'\n",
    "print '    mean accuracy', np.mean(linreg_accuracy_list)\n",
    "print '    mean MAE', np.mean(linreg_mae_list)\n",
    "print '    mean MSE', np.mean(linreg_mse_list)\n",
    "print '  not normed train'\n",
    "print '    mean accuracy', np.mean(linreg2_accuracy_list)\n",
    "print '    mean MAE', np.mean(linreg2_mae_list)\n",
    "print '    mean MSE', np.mean(linreg2_mse_list)\n",
    "\n",
    "print 'MultinomialNB'\n",
    "print '  normed train'\n",
    "print '    mean accuracy', np.mean(bayes_accuracy_list)\n",
    "print '    mean MAE', np.mean(bayes_mae_list)\n",
    "print '    mean MSE', np.mean(bayes_mse_list)\n",
    "print '  not normed train'\n",
    "print '    mean accuracy', np.mean(bayes2_accuracy_list)\n",
    "print '    mean MAE', np.mean(bayes2_mae_list)\n",
    "print '    mean MSE', np.mean(bayes2_mse_list)\n",
    "\n",
    "print 'LogisticRegression'\n",
    "print '  normed train'\n",
    "print '    mean accuracy', np.mean(logreg_accuracy_list)\n",
    "print '    mean MAE', np.mean(logreg_mae_list)\n",
    "print '    mean MSE', np.mean(logreg_mse_list)\n",
    "print '  not normed train'\n",
    "print '    mean accuracy', np.mean(logreg2_accuracy_list)\n",
    "print '    mean MAE', np.mean(logreg2_mae_list)\n",
    "print '    mean MSE', np.mean(logreg2_mse_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_best_text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), max_df=0.4, min_df=0.003)),\n",
    "                          ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                          ('clf', LinearRegression()),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_best_text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 2), min_df=0.001, max_df=0.3)),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_best_text_clf = Pipeline([('vect', CountVectorizer(max_df=0.3, min_df=0.001, ngram_range=(1, 2))),\n",
    "                          ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "                          ('clf', LogisticRegression(class_weight='balanced', penalty='l2')),\n",
    "                    ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
